{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydot) (3.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pydot\n",
    "%pip install tensorflow\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import (\n",
    "    DATA_INPUT_PATH,\n",
    "    MODEL_PATH,\n",
    "    METADATA_PATH,\n",
    ")\n",
    "\n",
    "from constants import CLASSES\n",
    "num_classes = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .csv(s) to dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in: data\n",
      "Found CSVs: [WindowsPath('data/physio_emg_imu_data_20250504_215905.csv')]\n",
      "\n",
      "Processing files and removing rows with incomplete landmarks:\n",
      "  Reading: physio_emg_imu_data_20250504_215905.csv\n",
      "    Dropped 155 rows due to missing landmarks.\n",
      "\n",
      "Shape before dropping duplicates across all files: (1985, 91)\n",
      "Shape after dropping duplicates: (1985, 91)\n"
     ]
    }
   ],
   "source": [
    "# --- Existing code before the loop ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Set your input path\n",
    "DATA_INPUT_PATH = Path(DATA_INPUT_PATH)\n",
    "\n",
    "# Find CSV files\n",
    "files = list(DATA_INPUT_PATH.glob(\"*.csv\"))\n",
    "print(\"Looking in:\", DATA_INPUT_PATH)\n",
    "print(\"Found CSVs:\", files)\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No CSV files found in {DATA_INPUT_PATH.resolve()}\")\n",
    "\n",
    "# --- NEW Modified Loop ---\n",
    "print(\"\\nProcessing files and removing rows with incomplete landmarks:\")\n",
    "for file in files:\n",
    "    print(f\"  Reading: {file.name}\")\n",
    "    # Read a single CSV\n",
    "    df_single = pd.read_csv(file)\n",
    "    initial_rows = len(df_single)\n",
    "\n",
    "    # Define landmark columns based on THIS file's columns\n",
    "    landmark_columns = [c for c in df_single.columns if c.endswith((\"_x_shldr_norm\", \"_y_shldr_norm\", \"_z_shldr_norm\"))]\n",
    "\n",
    "    if not landmark_columns:\n",
    "         print(f\"    WARNING: No landmark columns found in {file.name}. Skipping filtering for this file.\")\n",
    "    else:\n",
    "        # Drop rows with ANY NaN in the landmark columns for THIS file\n",
    "        df_single.dropna(subset=landmark_columns, inplace=True)\n",
    "        dropped_rows = initial_rows - len(df_single)\n",
    "        if dropped_rows > 0:\n",
    "            print(f\"    Dropped {dropped_rows} rows due to missing landmarks.\")\n",
    "\n",
    "    # Append the cleaned DataFrame (or original if no landmarks found/dropped)\n",
    "    if len(df_single) > 0:\n",
    "        dfs.append(df_single)\n",
    "    else:\n",
    "        print(f\"    WARNING: No rows remaining in {file.name} after filtering. Skipping this file.\")\n",
    "\n",
    "\n",
    "# --- Existing code after the loop ---\n",
    "# Concatenate into one DataFrame (only if dfs list is not empty)\n",
    "if not dfs:\n",
    "     raise ValueError(\"No dataframes to concatenate after filtering. Check input files and filtering logic.\")\n",
    "\n",
    "df = pd.concat(dfs, axis=0)\n",
    "\n",
    "# Remove duplicates (optional, but good practice)\n",
    "print(f\"\\nShape before dropping duplicates across all files: {df.shape}\")\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")\n",
    "\n",
    "# --- You no longer need the df.dropna() call here specifically for landmarks ---\n",
    "# --- as it was handled file-by-file above                                ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating calibration statistics from 'Rest' data...\n",
      "Landmark columns found (72): ['Pose_L_Shoulder_x_shldr_norm', 'Pose_L_Shoulder_y_shldr_norm', 'Pose_L_Shoulder_z_shldr_norm', 'Pose_L_Elbow_x_shldr_norm', 'Pose_L_Elbow_y_shldr_norm', 'Pose_L_Elbow_z_shldr_norm', 'Pose_L_Wrist_x_shldr_norm', 'Pose_L_Wrist_y_shldr_norm', 'Pose_L_Wrist_z_shldr_norm', 'Hand_R_Wrist_x_shldr_norm', 'Hand_R_Wrist_y_shldr_norm', 'Hand_R_Wrist_z_shldr_norm', 'Hand_R_Thumb_CMC_x_shldr_norm', 'Hand_R_Thumb_CMC_y_shldr_norm', 'Hand_R_Thumb_CMC_z_shldr_norm', 'Hand_R_Thumb_MCP_x_shldr_norm', 'Hand_R_Thumb_MCP_y_shldr_norm', 'Hand_R_Thumb_MCP_z_shldr_norm', 'Hand_R_Thumb_IP_x_shldr_norm', 'Hand_R_Thumb_IP_y_shldr_norm', 'Hand_R_Thumb_IP_z_shldr_norm', 'Hand_R_Thumb_Tip_x_shldr_norm', 'Hand_R_Thumb_Tip_y_shldr_norm', 'Hand_R_Thumb_Tip_z_shldr_norm', 'Hand_R_Index_MCP_x_shldr_norm', 'Hand_R_Index_MCP_y_shldr_norm', 'Hand_R_Index_MCP_z_shldr_norm', 'Hand_R_Index_PIP_x_shldr_norm', 'Hand_R_Index_PIP_y_shldr_norm', 'Hand_R_Index_PIP_z_shldr_norm', 'Hand_R_Index_DIP_x_shldr_norm', 'Hand_R_Index_DIP_y_shldr_norm', 'Hand_R_Index_DIP_z_shldr_norm', 'Hand_R_Index_Tip_x_shldr_norm', 'Hand_R_Index_Tip_y_shldr_norm', 'Hand_R_Index_Tip_z_shldr_norm', 'Hand_R_Middle_MCP_x_shldr_norm', 'Hand_R_Middle_MCP_y_shldr_norm', 'Hand_R_Middle_MCP_z_shldr_norm', 'Hand_R_Middle_PIP_x_shldr_norm', 'Hand_R_Middle_PIP_y_shldr_norm', 'Hand_R_Middle_PIP_z_shldr_norm', 'Hand_R_Middle_DIP_x_shldr_norm', 'Hand_R_Middle_DIP_y_shldr_norm', 'Hand_R_Middle_DIP_z_shldr_norm', 'Hand_R_Middle_Tip_x_shldr_norm', 'Hand_R_Middle_Tip_y_shldr_norm', 'Hand_R_Middle_Tip_z_shldr_norm', 'Hand_R_Ring_MCP_x_shldr_norm', 'Hand_R_Ring_MCP_y_shldr_norm', 'Hand_R_Ring_MCP_z_shldr_norm', 'Hand_R_Ring_PIP_x_shldr_norm', 'Hand_R_Ring_PIP_y_shldr_norm', 'Hand_R_Ring_PIP_z_shldr_norm', 'Hand_R_Ring_DIP_x_shldr_norm', 'Hand_R_Ring_DIP_y_shldr_norm', 'Hand_R_Ring_DIP_z_shldr_norm', 'Hand_R_Ring_Tip_x_shldr_norm', 'Hand_R_Ring_Tip_y_shldr_norm', 'Hand_R_Ring_Tip_z_shldr_norm', 'Hand_R_Pinky_MCP_x_shldr_norm', 'Hand_R_Pinky_MCP_y_shldr_norm', 'Hand_R_Pinky_MCP_z_shldr_norm', 'Hand_R_Pinky_PIP_x_shldr_norm', 'Hand_R_Pinky_PIP_y_shldr_norm', 'Hand_R_Pinky_PIP_z_shldr_norm', 'Hand_R_Pinky_DIP_x_shldr_norm', 'Hand_R_Pinky_DIP_y_shldr_norm', 'Hand_R_Pinky_DIP_z_shldr_norm', 'Hand_R_Pinky_Tip_x_shldr_norm', 'Hand_R_Pinky_Tip_y_shldr_norm', 'Hand_R_Pinky_Tip_z_shldr_norm']\n",
      "Calculated Calibration Mean (shape (8,)):\n",
      "[ 2.63  0.35  0.26  2.08  1.91 13.31 -0.23  7.9 ]\n",
      "Calculated Calibration StdDev (shape (8,)):\n",
      "[ 5.61  3.2   3.79  7.06  4.41 13.8   0.55  4.25]\n"
     ]
    }
   ],
   "source": [
    "# --- NEW CELL: Calculate Calibration Stats from 'Rest' Data ---\n",
    "import numpy as np\n",
    "from constants import NUM_EMG_SENSORS # Make sure NUM_EMG_SENSORS is defined in constants.py (should be 8)\n",
    "\n",
    "print(\"Calculating calibration statistics from 'Rest' data...\")\n",
    "\n",
    "# Select only the 'Rest' data (gesture_id == 0)\n",
    "rest_df = df[df['gesture_id'] == 0].copy()\n",
    "\n",
    "# Select only the EMG columns (s1 to s8)\n",
    "emg_columns = [f\"s{i}_norm\" for i in range(1, NUM_EMG_SENSORS + 1)]\n",
    "\n",
    "# Select only IMU columns (quat)\n",
    "imu_columns = [\"quat_w\",\"quatx\",\"quaty\",\"quatz\"]\n",
    "\n",
    "#select landmark columns based on your CSV header\n",
    "landmark_columns = [c for c in df.columns if c.endswith((\"_x_shldr_norm\", \"_y_shldr_norm\", \"_z_shldr_norm\"))]\n",
    "print(f\"Landmark columns found ({len(landmark_columns)}): {landmark_columns}\") # Add this print statement to verify\n",
    "\n",
    "rest_emg_data = rest_df[emg_columns].values # Get as numpy array\n",
    "\n",
    "if len(rest_emg_data) > 0:\n",
    "    # Calculate mean and std dev for each EMG channel (column-wise)\n",
    "    calibration_mean = np.mean(rest_emg_data, axis=0)\n",
    "    calibration_std = np.std(rest_emg_data, axis=0)\n",
    "\n",
    "    # Avoid division by zero: set std dev to 1 if it's 0 or very close to 0\n",
    "    calibration_std[calibration_std < 1e-6] = 1.0\n",
    "\n",
    "    print(f\"Calculated Calibration Mean (shape {calibration_mean.shape}):\\n{np.round(calibration_mean, 2)}\")\n",
    "    print(f\"Calculated Calibration StdDev (shape {calibration_std.shape}):\\n{np.round(calibration_std, 2)}\")\n",
    "else:\n",
    "    print(\"ERROR: No 'Rest' data found to calculate calibration statistics!\")\n",
    "    # Handle this error appropriately - maybe exit or use default values\n",
    "    # Using default values for now, but this indicates a data problem\n",
    "    calibration_mean = np.zeros(NUM_EMG_SENSORS)\n",
    "    calibration_std = np.ones(NUM_EMG_SENSORS)\n",
    "    print(\"Using default calibration stats (mean=0, std=1). CHECK YOUR DATA.\")\n",
    "\n",
    "# Ensure these variables are available for the next cell\n",
    "# (They will be if run in the same kernel session)\n",
    "# --- END OF NEW CELL ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All windows X_win shape: (79, 30, 12)\n",
      "All targets   Y    shape: (79, 72)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from constants import WINDOW_SIZE, WINDOW_STEP, NUM_EMG_SENSORS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# assume df, calibration_mean, calibration_std, landmark_columns etc. are already defined\n",
    "\n",
    "# define a real scaler object\n",
    "scaler = StandardScaler()\n",
    "scaler.mean_, scaler.scale_ = calibration_mean, calibration_std\n",
    "\n",
    "# build raw windows\n",
    "channels = [f\"s{i}_norm\" for i in range(1, NUM_EMG_SENSORS+1)] + [\"quat_w\",\"quatx\",\"quaty\",\"quatz\"]\n",
    "raw       = df[channels].values\n",
    "landmarks = df[landmark_columns].values\n",
    "\n",
    "X_win, Y = [], []\n",
    "for start in range(0, len(raw) - WINDOW_SIZE + 1, WINDOW_STEP):\n",
    "    win = raw[start:start+WINDOW_SIZE]\n",
    "    emg = win[:,:NUM_EMG_SENSORS]\n",
    "    imu = win[:,NUM_EMG_SENSORS:]\n",
    "    # use scaler here\n",
    "    norm_emg = scaler.transform(emg)\n",
    "    win_norm = np.concatenate([norm_emg, imu], axis=1)\n",
    "    X_win.append(win_norm)\n",
    "    center = start + WINDOW_SIZE//2\n",
    "    Y.append(landmarks[center])\n",
    "\n",
    "X_win = np.stack(X_win)\n",
    "Y     = np.array(Y)\n",
    "print(\"All windows X_win shape:\", X_win.shape)\n",
    "print(\"All targets   Y    shape:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, split, and one-shot encode RMS feature windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (47, 30, 12) (47, 72)\n",
      "Val:   (16, 30, 12) (16, 72)\n",
      "Test:  (16, 30, 12) (16, 72)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) train+val vs test\n",
    "X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n",
    "    X_win, Y, test_size=0.20, random_state=42\n",
    ")\n",
    "# 2) train vs val\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_trainval, Y_trainval, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, Y_train.shape)\n",
    "print(\"Val:  \", X_val.shape,   Y_val.shape)\n",
    "print(\"Test: \", X_test.shape,  Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, compile & train a simple dense classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reshape —\n",
      " Train: (47, 30, 12)\n",
      " Val:   (16, 30, 12)\n",
      " Test:  (16, 30, 12)\n",
      "Your network will produce 72 values per window (should equal Y.shape[1])\n",
      "NaN in X_train: False\n",
      "Inf in X_train: False\n",
      "NaN in X_val:   False\n",
      "Inf in X_val:   False\n",
      "NaN in Y_train: False\n",
      "Inf in Y_train: False\n",
      "NaN in Y_val:   False\n",
      "Inf in Y_val:   False\n",
      "X_train min/max: -2.16 / 25.08\n",
      "Y_train min/max: -0.80 / 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simpl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - loss: 0.3912 - mean_absolute_error: 0.4873 - val_loss: 0.0520 - val_mean_absolute_error: 0.1839\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1785 - mean_absolute_error: 0.3301 - val_loss: 0.0360 - val_mean_absolute_error: 0.1554\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1319 - mean_absolute_error: 0.2770 - val_loss: 0.0307 - val_mean_absolute_error: 0.1455\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0834 - mean_absolute_error: 0.2211 - val_loss: 0.0278 - val_mean_absolute_error: 0.1389\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0524 - mean_absolute_error: 0.1793 - val_loss: 0.0259 - val_mean_absolute_error: 0.1335\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0423 - mean_absolute_error: 0.1605 - val_loss: 0.0245 - val_mean_absolute_error: 0.1290\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0383 - mean_absolute_error: 0.1553 - val_loss: 0.0234 - val_mean_absolute_error: 0.1258\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0420 - mean_absolute_error: 0.1592 - val_loss: 0.0226 - val_mean_absolute_error: 0.1233\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0278 - mean_absolute_error: 0.1311 - val_loss: 0.0217 - val_mean_absolute_error: 0.1206\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0286 - mean_absolute_error: 0.1285 - val_loss: 0.0210 - val_mean_absolute_error: 0.1178\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0279 - mean_absolute_error: 0.1291 - val_loss: 0.0203 - val_mean_absolute_error: 0.1155\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0242 - mean_absolute_error: 0.1190 - val_loss: 0.0196 - val_mean_absolute_error: 0.1131\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0213 - mean_absolute_error: 0.1117 - val_loss: 0.0190 - val_mean_absolute_error: 0.1110\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0193 - mean_absolute_error: 0.1050 - val_loss: 0.0184 - val_mean_absolute_error: 0.1092\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0177 - mean_absolute_error: 0.1038 - val_loss: 0.0178 - val_mean_absolute_error: 0.1072\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0183 - mean_absolute_error: 0.1056 - val_loss: 0.0170 - val_mean_absolute_error: 0.1041\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0173 - mean_absolute_error: 0.1013 - val_loss: 0.0164 - val_mean_absolute_error: 0.1013\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - mean_absolute_error: 0.1012 - val_loss: 0.0161 - val_mean_absolute_error: 0.1002\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0157 - mean_absolute_error: 0.0969 - val_loss: 0.0157 - val_mean_absolute_error: 0.0985\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0139 - mean_absolute_error: 0.0889 - val_loss: 0.0152 - val_mean_absolute_error: 0.0965\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0160 - mean_absolute_error: 0.0945 - val_loss: 0.0149 - val_mean_absolute_error: 0.0951\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0150 - mean_absolute_error: 0.0922 - val_loss: 0.0144 - val_mean_absolute_error: 0.0932\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0117 - mean_absolute_error: 0.0822 - val_loss: 0.0140 - val_mean_absolute_error: 0.0914\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0140 - mean_absolute_error: 0.0903 - val_loss: 0.0134 - val_mean_absolute_error: 0.0888\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0116 - mean_absolute_error: 0.0824 - val_loss: 0.0127 - val_mean_absolute_error: 0.0860\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0110 - mean_absolute_error: 0.0813 - val_loss: 0.0122 - val_mean_absolute_error: 0.0842\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0114 - mean_absolute_error: 0.0817 - val_loss: 0.0119 - val_mean_absolute_error: 0.0827\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0102 - mean_absolute_error: 0.0775 - val_loss: 0.0116 - val_mean_absolute_error: 0.0813\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0100 - mean_absolute_error: 0.0748 - val_loss: 0.0113 - val_mean_absolute_error: 0.0800\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0081 - mean_absolute_error: 0.0680 - val_loss: 0.0110 - val_mean_absolute_error: 0.0787\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0098 - mean_absolute_error: 0.0740 - val_loss: 0.0107 - val_mean_absolute_error: 0.0773\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0089 - mean_absolute_error: 0.0709 - val_loss: 0.0106 - val_mean_absolute_error: 0.0767\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0114 - mean_absolute_error: 0.0778 - val_loss: 0.0104 - val_mean_absolute_error: 0.0762\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0103 - mean_absolute_error: 0.0736 - val_loss: 0.0102 - val_mean_absolute_error: 0.0753\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0091 - mean_absolute_error: 0.0696 - val_loss: 0.0100 - val_mean_absolute_error: 0.0744\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0093 - mean_absolute_error: 0.0706 - val_loss: 0.0099 - val_mean_absolute_error: 0.0736\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0087 - mean_absolute_error: 0.0689 - val_loss: 0.0098 - val_mean_absolute_error: 0.0727\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0081 - mean_absolute_error: 0.0674 - val_loss: 0.0096 - val_mean_absolute_error: 0.0716\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0084 - mean_absolute_error: 0.0689 - val_loss: 0.0095 - val_mean_absolute_error: 0.0711\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0073 - mean_absolute_error: 0.0640 - val_loss: 0.0094 - val_mean_absolute_error: 0.0704\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0072 - mean_absolute_error: 0.0635 - val_loss: 0.0093 - val_mean_absolute_error: 0.0698\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0082 - mean_absolute_error: 0.0657 - val_loss: 0.0091 - val_mean_absolute_error: 0.0691\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0068 - mean_absolute_error: 0.0607 - val_loss: 0.0090 - val_mean_absolute_error: 0.0691\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0072 - mean_absolute_error: 0.0592 - val_loss: 0.0090 - val_mean_absolute_error: 0.0693\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0073 - mean_absolute_error: 0.0615 - val_loss: 0.0090 - val_mean_absolute_error: 0.0692\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0075 - mean_absolute_error: 0.0652 - val_loss: 0.0090 - val_mean_absolute_error: 0.0689\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0070 - mean_absolute_error: 0.0615 - val_loss: 0.0089 - val_mean_absolute_error: 0.0684\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0062 - mean_absolute_error: 0.0567 - val_loss: 0.0089 - val_mean_absolute_error: 0.0678\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0095 - mean_absolute_error: 0.0690 - val_loss: 0.0089 - val_mean_absolute_error: 0.0677\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - mean_absolute_error: 0.0596 - val_loss: 0.0088 - val_mean_absolute_error: 0.0674\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0068 - mean_absolute_error: 0.0597 - val_loss: 0.0088 - val_mean_absolute_error: 0.0672\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0072 - mean_absolute_error: 0.0605 - val_loss: 0.0087 - val_mean_absolute_error: 0.0673\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0093 - mean_absolute_error: 0.0671 - val_loss: 0.0087 - val_mean_absolute_error: 0.0670\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - mean_absolute_error: 0.0606 - val_loss: 0.0086 - val_mean_absolute_error: 0.0666\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - mean_absolute_error: 0.0589 - val_loss: 0.0086 - val_mean_absolute_error: 0.0661\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - mean_absolute_error: 0.0527 - val_loss: 0.0085 - val_mean_absolute_error: 0.0655\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - mean_absolute_error: 0.0558 - val_loss: 0.0084 - val_mean_absolute_error: 0.0650\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - mean_absolute_error: 0.0525 - val_loss: 0.0082 - val_mean_absolute_error: 0.0642\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - mean_absolute_error: 0.0542 - val_loss: 0.0081 - val_mean_absolute_error: 0.0636\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0061 - mean_absolute_error: 0.0577 - val_loss: 0.0080 - val_mean_absolute_error: 0.0634\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0061 - mean_absolute_error: 0.0586 - val_loss: 0.0079 - val_mean_absolute_error: 0.0630\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0062 - mean_absolute_error: 0.0558 - val_loss: 0.0078 - val_mean_absolute_error: 0.0627\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0061 - mean_absolute_error: 0.0559 - val_loss: 0.0078 - val_mean_absolute_error: 0.0624\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - mean_absolute_error: 0.0524 - val_loss: 0.0078 - val_mean_absolute_error: 0.0624\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - mean_absolute_error: 0.0493 - val_loss: 0.0078 - val_mean_absolute_error: 0.0623\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - mean_absolute_error: 0.0527 - val_loss: 0.0078 - val_mean_absolute_error: 0.0621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0068 - mean_absolute_error: 0.0576\n",
      "Final test MSE: 0.0068, MAE: 0.0576\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- BEGIN shape‐fix (unchanged) -------\n",
    "def ensure_3d(X, window_size, n_channels):\n",
    "    if X.ndim == 3:\n",
    "        return X\n",
    "    if X.ndim == 2 and X.shape[1] == n_channels:\n",
    "        n_samples = X.shape[0]\n",
    "        return X.reshape(n_samples, window_size, n_channels)\n",
    "    raise ValueError(f\"Cannot reshape array of shape {X.shape} into 3D with {window_size}×{n_channels}\")\n",
    "\n",
    "X_train = ensure_3d(X_train, WINDOW_SIZE, 12)\n",
    "X_val   = ensure_3d(X_val,   WINDOW_SIZE, 12)\n",
    "X_test  = ensure_3d(X_test,  WINDOW_SIZE, 12)\n",
    "\n",
    "print(\"After reshape —\")\n",
    "print(\" Train:\", X_train.shape)\n",
    "print(\" Val:  \", X_val.shape)\n",
    "print(\" Test: \", X_test.shape)\n",
    "# --- END shape‐fix -------\n",
    "\n",
    "# dynamically pick up how many outputs your Y has\n",
    "n_outputs = Y_train.shape[1]\n",
    "print(\"Your network will produce\", n_outputs, \"values per window (should equal Y.shape[1])\")\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(WINDOW_SIZE, 12)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    # match the number of target‐dimensions\n",
    "    Dense(n_outputs, activation=\"linear\")\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss=MeanSquaredError(),\n",
    "    metrics=[MeanAbsoluteError()]\n",
    ")\n",
    "\n",
    "# Check for NaN/inf in input data\n",
    "print(f\"NaN in X_train: {np.any(np.isnan(X_train))}\")\n",
    "print(f\"Inf in X_train: {np.any(np.isinf(X_train))}\")\n",
    "print(f\"NaN in X_val:   {np.any(np.isnan(X_val))}\")\n",
    "print(f\"Inf in X_val:   {np.any(np.isinf(X_val))}\")\n",
    "\n",
    "# Check for NaN/inf in target data\n",
    "print(f\"NaN in Y_train: {np.any(np.isnan(Y_train))}\")\n",
    "print(f\"Inf in Y_train: {np.any(np.isinf(Y_train))}\")\n",
    "print(f\"NaN in Y_val:   {np.any(np.isnan(Y_val))}\")\n",
    "print(f\"Inf in Y_val:   {np.any(np.isinf(Y_val))}\")\n",
    "\n",
    "# Also check the ranges\n",
    "print(f\"X_train min/max: {np.min(X_train):.2f} / {np.max(X_train):.2f}\")\n",
    "print(f\"Y_train min/max: {np.min(Y_train):.2f} / {np.max(Y_train):.2f}\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=100,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_mse, test_mae = model.evaluate(X_test, Y_test)\n",
    "print(f\"Final test MSE: {test_mse:.4f}, MAE: {test_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model and the scalar + feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to model\\physio_model.h5\n",
      "Saved metadata (scaler, features, calib_mean, calib_std) to model\\physio_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- MODIFIED CELL 8: Save Model and Metadata ---\n",
    "# make sure the folder exists\n",
    "(Path(MODEL_PATH).parent).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Saved model to\", MODEL_PATH)\n",
    "\n",
    "# Save the scaler, feature names, and calibration stats to METADATA_PATH\n",
    "with open(METADATA_PATH, \"wb\") as f:\n",
    "    feature_names = [f\"s{i}_norm\" for i in range(1, NUM_EMG_SENSORS + 1)] + [\"quat_w\", \"quatx\", \"quaty\", \"quatz\"]\n",
    "    pickle.dump((scaler, feature_names, calibration_mean, calibration_std), f)\n",
    "    print(\"Saved metadata (scaler, features, calib_mean, calib_std) to\", METADATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_INPUT_PATH -> data\n",
      "  contains: ['artemis_archive', 'convert_old_data.py', 'physio_emg_imu_data_20250504_215905.csv']\n",
      "\n",
      "MODEL_INPUT_PATH -> model\n",
      "  contains: ['artemis_archive', 'physio_metadata.pkl', 'physio_model.h5']\n",
      "\n",
      "MODEL_PATH       -> model\\physio_model.h5 exists? True\n",
      "METADATA_PATH    -> model\\physio_metadata.pkl exists? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from constants import DATA_INPUT_PATH, MODEL_INPUT_PATH, MODEL_PATH, METADATA_PATH\n",
    "\n",
    "print(\"DATA_INPUT_PATH ->\", DATA_INPUT_PATH)\n",
    "print(\"  contains:\", os.listdir(DATA_INPUT_PATH))\n",
    "print()\n",
    "print(\"MODEL_INPUT_PATH ->\", MODEL_INPUT_PATH)\n",
    "print(\"  contains:\", os.listdir(MODEL_INPUT_PATH))\n",
    "print()\n",
    "print(\"MODEL_PATH       ->\", MODEL_PATH, \"exists?\", os.path.exists(MODEL_PATH))\n",
    "print(\"METADATA_PATH    ->\", METADATA_PATH, \"exists?\", os.path.exists(METADATA_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simpl\\Desktop\\coding\\NeuroSyn\\model-v4\\constants.py\n"
     ]
    }
   ],
   "source": [
    "import constants\n",
    "print(constants.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  not enough samples for 'Wrist Flexion' (need 30, got 0)\n",
      "⚠️  not enough samples for 'Elbow Extension' (need 30, got 0)\n",
      "⚠️  not enough samples for 'Hand Open' (need 30, got 0)\n",
      "Demo results:\n",
      " • True:  0 Rest              → Predicted: [-0.05292831  0.07073354  0.07009118  0.15387936  0.1850755  -0.18561047\n",
      "  0.02915647  0.20194347 -0.47631323 -0.02728528  0.16244575  0.25640112\n",
      " -0.07797333  0.09802471  0.22471485 -0.04472312  0.2650513   0.22484468\n",
      " -0.0612967   0.1808976   0.00906982 -0.09162341  0.24221587  0.10663012\n",
      " -0.11510002  0.16116682  0.3088908  -0.1302991   0.1391977   0.10235903\n",
      " -0.16996616  0.20987767  0.15430072 -0.10079712  0.19445735  0.16658682\n",
      " -0.10289496  0.22714487  0.16622005 -0.09545696  0.24737702  0.1678516\n",
      "  0.02294839  0.26204786  0.05826973 -0.06669929  0.22454369  0.17451546\n",
      " -0.06131237  0.2505746   0.08363113 -0.03796579  0.19722764  0.05711849\n",
      " -0.00330704  0.21310142  0.12974313 -0.04157147  0.22107364  0.0658411\n",
      "  0.01679794  0.26168633  0.12070472  0.00460037  0.17919718  0.09405581\n",
      " -0.01451925  0.17820348  0.03191902 -0.03781092  0.2714418   0.16922028]\n",
      " • True:  2 Wrist Extension   → Predicted: [-3.99917066e-02  5.99032193e-02  7.84357116e-02  1.48771510e-01\n",
      "  1.66897804e-01 -1.93420798e-01  2.20149197e-02  1.99673295e-01\n",
      " -4.40074921e-01  3.52581963e-04  1.35250226e-01  2.24048972e-01\n",
      " -7.31651187e-02  9.59482491e-02  2.18875796e-01 -4.99048382e-02\n",
      "  2.37182081e-01  2.07200199e-01 -6.63531497e-02  2.10380673e-01\n",
      "  7.24793226e-03 -5.99100590e-02  2.23214447e-01  9.69587788e-02\n",
      " -1.28117010e-01  1.57325283e-01  2.63138473e-01 -1.16740018e-01\n",
      "  1.38585046e-01  1.03038691e-01 -1.47956342e-01  1.96340740e-01\n",
      "  1.30624175e-01 -9.12961438e-02  1.87599480e-01  1.33564815e-01\n",
      " -1.13744095e-01  2.16374412e-01  1.69462264e-01 -9.60187316e-02\n",
      "  2.23780289e-01  1.58860594e-01  3.40448767e-02  2.52167523e-01\n",
      "  6.93327263e-02 -7.67689869e-02  2.05714971e-01  1.59314305e-01\n",
      " -6.22319505e-02  2.08021522e-01  6.79777861e-02 -1.08577507e-02\n",
      "  2.00850457e-01  8.28874707e-02 -1.76345073e-02  1.85167968e-01\n",
      "  1.41620219e-01 -1.59889534e-02  2.15752929e-01  6.12490587e-02\n",
      "  3.86667140e-02  2.54412234e-01  1.27310798e-01  6.93608169e-03\n",
      "  1.90008074e-01  8.83949474e-02 -5.52499527e-03  1.53645575e-01\n",
      "  2.69826204e-02 -1.38372835e-02  2.39323393e-01  1.69011846e-01]\n",
      " • True:  3 Elbow Flexion     → Predicted: [-0.02622377  0.06686576  0.07133637  0.1544578   0.15681672 -0.1951924\n",
      "  0.01305183  0.20400831 -0.41280478  0.01406006  0.12425828  0.22302379\n",
      " -0.07730661  0.09433849  0.222646   -0.06314859  0.23314486  0.20290805\n",
      " -0.06998633  0.22522439  0.00648974 -0.03962678  0.22938642  0.0984041\n",
      " -0.13136111  0.16561022  0.26247808 -0.11340974  0.13035107  0.09208966\n",
      " -0.13947153  0.19899277  0.10997275 -0.07755132  0.1987976   0.11678138\n",
      " -0.11697409  0.22468977  0.17221214 -0.09634657  0.22183242  0.16394909\n",
      "  0.04066826  0.25478354  0.07363383 -0.08411081  0.21804956  0.16156134\n",
      " -0.05463156  0.20178396  0.06698336 -0.0019681   0.21260318  0.09694264\n",
      " -0.01602095  0.18784907  0.14049971  0.00221541  0.20827849  0.04526069\n",
      "  0.05103025  0.25308383  0.11636318  0.01929886  0.19858277  0.08123997\n",
      "  0.01135752  0.14934266  0.02006164  0.00407192  0.23054945  0.16901515]\n",
      " • True:  5 Hand Close        → Predicted: [-0.02780534  0.04812639  0.04619235  0.10457743  0.17780924 -0.2008792\n",
      "  0.0283363   0.19911233 -0.38441524  0.0160051   0.13361296  0.18683937\n",
      " -0.03245722  0.11195557  0.18009762 -0.0263089   0.21745378  0.1623174\n",
      " -0.05043129  0.2070145   0.06791107 -0.03579111  0.20330125  0.10589197\n",
      " -0.10546191  0.14997585  0.21122308 -0.07498576  0.12291149  0.1132055\n",
      " -0.10179743  0.1758718   0.12565434 -0.06785127  0.19147204  0.10295587\n",
      " -0.08202338  0.20601445  0.16752379 -0.06963549  0.19319265  0.13430716\n",
      "  0.00630911  0.20516956  0.08173902 -0.05301009  0.19887887  0.15517825\n",
      " -0.05992051  0.18472743  0.09200405 -0.01697234  0.19768165  0.11134349\n",
      " -0.01334475  0.1931997   0.1398054  -0.00244533  0.20195597  0.04533101\n",
      "  0.03485925  0.20204185  0.12520117  0.02318971  0.18582916  0.08089566\n",
      " -0.0126901   0.13947544  0.06478059  0.00689328  0.21441436  0.1518685 ]\n",
      " • True:  7 Forearm Pronation → Predicted: [-0.03988606  0.0537594   0.07288275  0.14075264  0.17135078 -0.1896174\n",
      "  0.02339333  0.19569395 -0.43756032 -0.00149175  0.14049515  0.2172226\n",
      " -0.06731599  0.10167557  0.21039033 -0.04478222  0.2319793   0.20149717\n",
      " -0.06378639  0.20258924  0.01603574 -0.06364203  0.2160086   0.09706918\n",
      " -0.12010863  0.15331246  0.25180098 -0.11214699  0.14081176  0.1057882\n",
      " -0.14219588  0.19092275  0.13298033 -0.091554    0.18069644  0.135093\n",
      " -0.10479908  0.20801693  0.1644519  -0.09047399  0.2175624   0.15308864\n",
      "  0.02779076  0.24289098  0.0687741  -0.07094431  0.19651455  0.15374042\n",
      " -0.05962821  0.20471793  0.07213026 -0.01239869  0.19381289  0.0818415\n",
      " -0.0185796   0.18161213  0.13916346 -0.02115916  0.21185707  0.06691261\n",
      "  0.03293098  0.24673432  0.1294111   0.0030782   0.18552008  0.09139486\n",
      " -0.00932755  0.15532693  0.03402909 -0.01752969  0.23481286  0.16393134]\n",
      " • True:  8 Forearm Supination → Predicted: [-0.04177127  0.04772225  0.06934426  0.13336009  0.17644753 -0.18624362\n",
      "  0.02580781  0.19180872 -0.43940324 -0.00496794  0.14637204  0.21176955\n",
      " -0.06192461  0.10660444  0.20288947 -0.03868318  0.22828951  0.19743353\n",
      " -0.06116043  0.19407174  0.02335324 -0.0696085   0.20921344  0.09695274\n",
      " -0.11307447  0.14883403  0.24259505 -0.10885614  0.1438177   0.10961185\n",
      " -0.1386856   0.18609837  0.13787091 -0.09373409  0.17342983  0.13875037\n",
      " -0.09699859  0.1999701   0.1599479  -0.08587851  0.21274066  0.14762494\n",
      "  0.0217117   0.23490646  0.06769983 -0.06511463  0.18720055  0.14884615\n",
      " -0.05858083  0.20290126  0.07567909 -0.01493598  0.18635648  0.07897044\n",
      " -0.01958598  0.17831117  0.1373086  -0.02800771  0.20973167  0.07384849\n",
      "  0.02645504  0.24062613  0.13270198 -0.00185718  0.18061036  0.09488054\n",
      " -0.01486487  0.15732247  0.04080077 -0.02312369  0.23236933  0.15976316]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "from constants import DATA_INPUT_PATH, MODEL_PATH, METADATA_PATH, CLASSES, WINDOW_SIZE, NUM_EMG_SENSORS\n",
    "\n",
    "# 1) Load the freshest CSV\n",
    "data_dir = Path(DATA_INPUT_PATH)\n",
    "csv_path = max(data_dir.glob(\"*.csv\"), key=lambda p: p.stat().st_mtime)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Load scaler + feature names\n",
    "with open(METADATA_PATH, \"rb\") as f:\n",
    "    scaler, feature_names, calibration_mean, calibration_std = pickle.load(f)\n",
    "\n",
    "# 3) Load your trained model\n",
    "model = load_model(MODEL_PATH, compile=False)\n",
    "\n",
    "# 4) For each class, grab the first valid window and predict\n",
    "demo_rows = []\n",
    "for gid, name in CLASSES.items():\n",
    "    sub = df[df[\"gesture_id\"] == gid]\n",
    "    if len(sub) < WINDOW_SIZE:\n",
    "        print(f\"⚠️  not enough samples for '{name}' (need {WINDOW_SIZE}, got {len(sub)})\")\n",
    "        continue\n",
    "\n",
    "    # Get the first window for this gesture\n",
    "    window = sub[feature_names].values[:WINDOW_SIZE]  # shape (30, 12)\n",
    "    # Separate EMG/IMU parts\n",
    "    emg_part = window[:, :NUM_EMG_SENSORS]\n",
    "    imu_part = window[:, NUM_EMG_SENSORS:]\n",
    "\n",
    "    # Normalize EMG part using loaded stats\n",
    "    normalized_emg_part = (emg_part - calibration_mean) / calibration_std\n",
    "\n",
    "    # Concatenate normalized EMG and raw IMU\n",
    "    window_norm = np.concatenate([normalized_emg_part, imu_part], axis=1)  # shape (30, 12)\n",
    "    demo_rows.append((gid, name, window_norm))\n",
    "\n",
    "# Assemble demo set\n",
    "y_true = [gid for gid, _, _ in demo_rows]\n",
    "X_demo = np.stack([vec for *_, vec in demo_rows])  # shape (N, 30, 12)\n",
    "\n",
    "# 5) Predict\n",
    "preds = model.predict(X_demo, verbose=0)\n",
    "# If this is a regression model, you may want to print the predictions directly.\n",
    "# If it's a classification model, use argmax:\n",
    "# pred_ids = preds.argmax(axis=1)\n",
    "\n",
    "print(\"Demo results:\")\n",
    "for (true_id, true_name, _), pred in zip(demo_rows, preds):\n",
    "    print(f\" • True: {true_id:2d} {true_name:17s} → Predicted: {pred}\")\n",
    "\n",
    "# If you want to compute accuracy for classification:\n",
    "# acc = np.mean(np.array(pred_ids) == np.array(y_true))\n",
    "# print(f\"\\nDemo accuracy (window per class): {acc:.0%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
