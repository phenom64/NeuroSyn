{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydot) (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\blacb\\appdata\\roaming\\python\\python312\\site-packages (2.17.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.1 in c:\\users\\blacb\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\blacb\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\blacb\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pydot\n",
    "%pip install tensorflow\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import (\n",
    "    DATA_INPUT_PATH,\n",
    "    MODEL_PATH,\n",
    "    METADATA_PATH,\n",
    ")\n",
    "\n",
    "from constants import CLASSES\n",
    "num_classes = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .csv(s) to dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in: data\n",
      "Found CSVs: [WindowsPath('data/physio_emg_imu_data_20250429_001144.csv'), WindowsPath('data/physio_emg_imu_data_20250429_174128.csv'), WindowsPath('data/physio_emg_imu_data_20250429_175521.csv'), WindowsPath('data/physio_emg_imu_data_20250430_002614.csv')]\n",
      "Shape before dropping duplicates: (42037, 16)\n",
      "Shape after dropping duplicates: (42037, 16)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Set your input path\n",
    "DATA_INPUT_PATH = Path(DATA_INPUT_PATH)  \n",
    "\n",
    "# Find CSV files\n",
    "files = list(DATA_INPUT_PATH.glob(\"*.csv\"))\n",
    "print(\"Looking in:\", DATA_INPUT_PATH)\n",
    "print(\"Found CSVs:\", files)\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No CSV files found in {DATA_INPUT_PATH.resolve()}\")\n",
    "\n",
    "# Read all files\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "df = pd.concat(dfs, axis=0)\n",
    "\n",
    "# Reorder/select columns (if applicable)\n",
    "\n",
    "# Remove duplicates\n",
    "print(f\"Shape before dropping duplicates: {df.shape}\")\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating calibration statistics from 'Rest' data...\n",
      "Landmark columns are: ['quat_x', 'quat_y', 'quat_z']\n",
      "Calculated Calibration Mean (shape (8,)):\n",
      "[78.91 52.52 40.85 40.06 60.6  77.78 71.22 61.55]\n",
      "Calculated Calibration StdDev (shape (8,)):\n",
      "[78.76 51.92 19.09 13.64 29.51 71.93 43.05 41.06]\n"
     ]
    }
   ],
   "source": [
    "# --- NEW CELL: Calculate Calibration Stats from 'Rest' Data ---\n",
    "import numpy as np\n",
    "from constants import NUM_EMG_SENSORS # Make sure NUM_EMG_SENSORS is defined in constants.py (should be 8)\n",
    "\n",
    "print(\"Calculating calibration statistics from 'Rest' data...\")\n",
    "\n",
    "# Select only the 'Rest' data (gesture_id == 0)\n",
    "rest_df = df[df['gesture_id'] == 0].copy()\n",
    "\n",
    "# Select only the EMG columns (s1 to s8)\n",
    "emg_columns = [f\"s{i}\" for i in range(1, NUM_EMG_SENSORS + 1)]\n",
    "\n",
    "# Select only IMU columns (quat)\n",
    "imu_columns = [\"quat_w\",\"quatx\",\"quaty\",\"quatz\"]\n",
    "\n",
    "# Get landmark data\n",
    "landmark_columns = [c for c in df.columns if c.endswith((\"_x\",\"_y\",\"_z\"))]\n",
    "print(f\"Landmark columns are: {landmark_columns}\")\n",
    "\n",
    "rest_emg_data = rest_df[emg_columns].values # Get as numpy array\n",
    "\n",
    "if len(rest_emg_data) > 0:\n",
    "    # Calculate mean and std dev for each EMG channel (column-wise)\n",
    "    calibration_mean = np.mean(rest_emg_data, axis=0)\n",
    "    calibration_std = np.std(rest_emg_data, axis=0)\n",
    "\n",
    "    # Avoid division by zero: set std dev to 1 if it's 0 or very close to 0\n",
    "    calibration_std[calibration_std < 1e-6] = 1.0\n",
    "\n",
    "    print(f\"Calculated Calibration Mean (shape {calibration_mean.shape}):\\n{np.round(calibration_mean, 2)}\")\n",
    "    print(f\"Calculated Calibration StdDev (shape {calibration_std.shape}):\\n{np.round(calibration_std, 2)}\")\n",
    "else:\n",
    "    print(\"ERROR: No 'Rest' data found to calculate calibration statistics!\")\n",
    "    # Handle this error appropriately - maybe exit or use default values\n",
    "    # Using default values for now, but this indicates a data problem\n",
    "    calibration_mean = np.zeros(NUM_EMG_SENSORS)\n",
    "    calibration_std = np.ones(NUM_EMG_SENSORS)\n",
    "    print(\"Using default calibration stats (mean=0, std=1). CHECK YOUR DATA.\")\n",
    "\n",
    "# Ensure these variables are available for the next cell\n",
    "# (They will be if run in the same kernel session)\n",
    "# --- END OF NEW CELL ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['quatx', 'quaty', 'quatz'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# build raw windows\u001b[39;00m\n\u001b[0;32m     12\u001b[0m channels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EMG_SENSORS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquat_w\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquatx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquaty\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquatz\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m raw       \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     14\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m df[landmark_columns]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     16\u001b[0m X_win, Y \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\blacb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\blacb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\blacb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['quatx', 'quaty', 'quatz'] not in index\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from constants import WINDOW_SIZE, WINDOW_STEP, NUM_EMG_SENSORS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# assume df, calibration_mean, calibration_std, landmark_columns etc. are already defined\n",
    "\n",
    "# define a real scaler object\n",
    "scaler = StandardScaler()\n",
    "scaler.mean_, scaler.scale_ = calibration_mean, calibration_std\n",
    "\n",
    "# build raw windows\n",
    "channels = [f\"s{i}\" for i in range(1, NUM_EMG_SENSORS+1)] + [\"quat_w\",\"quatx\",\"quaty\",\"quatz\"]\n",
    "raw       = df[channels].values\n",
    "landmarks = df[landmark_columns].values\n",
    "\n",
    "X_win, Y = [], []\n",
    "for start in range(0, len(raw) - WINDOW_SIZE + 1, WINDOW_STEP):\n",
    "    win = raw[start:start+WINDOW_SIZE]\n",
    "    emg = win[:,:NUM_EMG_SENSORS]\n",
    "    imu = win[:,NUM_EMG_SENSORS:]\n",
    "    # use scaler here\n",
    "    norm_emg = scaler.transform(emg)\n",
    "    win_norm = np.concatenate([norm_emg, imu], axis=1)\n",
    "    X_win.append(win_norm)\n",
    "    center = start + WINDOW_SIZE//2\n",
    "    Y.append(landmarks[center])\n",
    "\n",
    "X_win = np.stack(X_win)\n",
    "Y     = np.array(Y)\n",
    "print(\"All windows X_win shape:\", X_win.shape)\n",
    "print(\"All targets   Y    shape:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, split, and one-shot encode RMS feature windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (252, 30, 12) (252, 72)\n",
      "Val:   (84, 30, 12) (84, 72)\n",
      "Test:  (84, 30, 12) (84, 72)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) train+val vs test\n",
    "X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n",
    "    X_win, Y, test_size=0.20, random_state=42\n",
    ")\n",
    "# 2) train vs val\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_trainval, Y_trainval, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, Y_train.shape)\n",
    "print(\"Val:  \", X_val.shape,   Y_val.shape)\n",
    "print(\"Test: \", X_test.shape,  Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, compile & train a simple dense classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reshape —\n",
      " Train: (252, 30, 12)\n",
      " Val:   (84, 30, 12)\n",
      " Test:  (84, 30, 12)\n",
      "Your network will produce 72 values per window (should equal Y.shape[1])\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blacb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.6342 - mae: 0.5897 - val_loss: 0.8875 - val_mae: 0.6279\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2977 - mae: 0.4197 - val_loss: 0.3477 - val_mae: 0.4213\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1947 - mae: 0.3415 - val_loss: 0.2212 - val_mae: 0.3508\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1460 - mae: 0.3001 - val_loss: 0.1785 - val_mae: 0.3220\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1210 - mae: 0.2720 - val_loss: 0.1472 - val_mae: 0.2966\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1016 - mae: 0.2503 - val_loss: 0.1245 - val_mae: 0.2740\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0900 - mae: 0.2348 - val_loss: 0.1093 - val_mae: 0.2560\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0787 - mae: 0.2199 - val_loss: 0.0994 - val_mae: 0.2429\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0687 - mae: 0.2047 - val_loss: 0.0922 - val_mae: 0.2326\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0614 - mae: 0.1939 - val_loss: 0.0866 - val_mae: 0.2249\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0551 - mae: 0.1822 - val_loss: 0.0815 - val_mae: 0.2184\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0502 - mae: 0.1737 - val_loss: 0.0768 - val_mae: 0.2125\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0424 - mae: 0.1597 - val_loss: 0.0728 - val_mae: 0.2071\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0412 - mae: 0.1560 - val_loss: 0.0690 - val_mae: 0.2015\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0366 - mae: 0.1476 - val_loss: 0.0647 - val_mae: 0.1949\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0352 - mae: 0.1439 - val_loss: 0.0608 - val_mae: 0.1888\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0290 - mae: 0.1314 - val_loss: 0.0573 - val_mae: 0.1829\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0277 - mae: 0.1279 - val_loss: 0.0542 - val_mae: 0.1778\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0247 - mae: 0.1202 - val_loss: 0.0512 - val_mae: 0.1732\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0235 - mae: 0.1174 - val_loss: 0.0482 - val_mae: 0.1681\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0210 - mae: 0.1112 - val_loss: 0.0456 - val_mae: 0.1634\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0202 - mae: 0.1087 - val_loss: 0.0434 - val_mae: 0.1590\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0190 - mae: 0.1040 - val_loss: 0.0408 - val_mae: 0.1544\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0178 - mae: 0.1015 - val_loss: 0.0393 - val_mae: 0.1520\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0167 - mae: 0.0992 - val_loss: 0.0378 - val_mae: 0.1492\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0146 - mae: 0.0924 - val_loss: 0.0355 - val_mae: 0.1445\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0143 - mae: 0.0904 - val_loss: 0.0333 - val_mae: 0.1396\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0133 - mae: 0.0879 - val_loss: 0.0323 - val_mae: 0.1372\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0122 - mae: 0.0838 - val_loss: 0.0315 - val_mae: 0.1355\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0120 - mae: 0.0827 - val_loss: 0.0285 - val_mae: 0.1284\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0107 - mae: 0.0788 - val_loss: 0.0268 - val_mae: 0.1244\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0095 - mae: 0.0748 - val_loss: 0.0251 - val_mae: 0.1202\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0098 - mae: 0.0758 - val_loss: 0.0241 - val_mae: 0.1178\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0783 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0087 - mae: 0.0707 - val_loss: 0.0223 - val_mae: 0.1131\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0095 - mae: 0.0740 - val_loss: 0.0196 - val_mae: 0.1048\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0083 - mae: 0.0690 - val_loss: 0.0183 - val_mae: 0.1009\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0078 - mae: 0.0665 - val_loss: 0.0189 - val_mae: 0.1030\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0070 - mae: 0.0629 - val_loss: 0.0187 - val_mae: 0.1027\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0074 - mae: 0.0650 - val_loss: 0.0173 - val_mae: 0.0981\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0065 - mae: 0.0605 - val_loss: 0.0154 - val_mae: 0.0912\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0074 - mae: 0.0639 - val_loss: 0.0147 - val_mae: 0.0891\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0143 - val_mae: 0.0884\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0069 - mae: 0.0618 - val_loss: 0.0143 - val_mae: 0.0884\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0570 - val_loss: 0.0136 - val_mae: 0.0857\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0058 - mae: 0.0569 - val_loss: 0.0128 - val_mae: 0.0825\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0050 - mae: 0.0534 - val_loss: 0.0120 - val_mae: 0.0791\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0059 - mae: 0.0568 - val_loss: 0.0116 - val_mae: 0.0775\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0115 - val_mae: 0.0766\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0050 - mae: 0.0516 - val_loss: 0.0105 - val_mae: 0.0722\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - mae: 0.0528 - val_loss: 0.0101 - val_mae: 0.0710\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0529 - val_loss: 0.0102 - val_mae: 0.0719\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0499 - val_loss: 0.0101 - val_mae: 0.0707\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0048 - mae: 0.0509 - val_loss: 0.0094 - val_mae: 0.0666\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0046 - mae: 0.0490 - val_loss: 0.0087 - val_mae: 0.0640\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0041 - mae: 0.0466 - val_loss: 0.0082 - val_mae: 0.0607\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0485 - val_loss: 0.0082 - val_mae: 0.0620\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042 - mae: 0.0474 - val_loss: 0.0081 - val_mae: 0.0605\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0047 - mae: 0.0498 - val_loss: 0.0079 - val_mae: 0.0592\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0039 - mae: 0.0454 - val_loss: 0.0077 - val_mae: 0.0589\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0039 - mae: 0.0459 - val_loss: 0.0077 - val_mae: 0.0585\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0034 - mae: 0.0429 - val_loss: 0.0070 - val_mae: 0.0525\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039 - mae: 0.0449 - val_loss: 0.0069 - val_mae: 0.0530\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0041 - mae: 0.0468 - val_loss: 0.0075 - val_mae: 0.0583\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0034 - mae: 0.0423 - val_loss: 0.0068 - val_mae: 0.0551\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0036 - mae: 0.0427 - val_loss: 0.0057 - val_mae: 0.0459\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mae: 0.0439 - val_loss: 0.0057 - val_mae: 0.0462\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0037 - mae: 0.0435 - val_loss: 0.0058 - val_mae: 0.0481\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0030 - mae: 0.0396 - val_loss: 0.0060 - val_mae: 0.0491\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0036 - mae: 0.0431 - val_loss: 0.0058 - val_mae: 0.0466\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0383 \n",
      "Final test MSE: 0.0032, MAE: 0.0379\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- BEGIN shape‐fix (unchanged) -------\n",
    "def ensure_3d(X, window_size, n_channels):\n",
    "    if X.ndim == 3:\n",
    "        return X\n",
    "    if X.ndim == 2 and X.shape[1] == n_channels:\n",
    "        n_samples = X.shape[0]\n",
    "        return X.reshape(n_samples, window_size, n_channels)\n",
    "    raise ValueError(f\"Cannot reshape array of shape {X.shape} into 3D with {window_size}×{n_channels}\")\n",
    "\n",
    "X_train = ensure_3d(X_train, WINDOW_SIZE, 12)\n",
    "X_val   = ensure_3d(X_val,   WINDOW_SIZE, 12)\n",
    "X_test  = ensure_3d(X_test,  WINDOW_SIZE, 12)\n",
    "\n",
    "print(\"After reshape —\")\n",
    "print(\" Train:\", X_train.shape)\n",
    "print(\" Val:  \", X_val.shape)\n",
    "print(\" Test: \", X_test.shape)\n",
    "# --- END shape‐fix -------\n",
    "\n",
    "# dynamically pick up how many outputs your Y has\n",
    "n_outputs = Y_train.shape[1]\n",
    "print(\"Your network will produce\", n_outputs, \"values per window (should equal Y.shape[1])\")\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(WINDOW_SIZE, 12)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    # match the number of target‐dimensions\n",
    "    Dense(n_outputs, activation=\"linear\")\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_mse, test_mae = model.evaluate(X_test, Y_test)\n",
    "print(f\"Final test MSE: {test_mse:.4f}, MAE: {test_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model and the scalar + feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to model\\physio_model.h5\n",
      "Saved metadata (scaler, features, calib_mean, calib_std) to model-v4\\model_temp\\physio_temp_meta.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- MODIFIED CELL 8: Save Model and Metadata ---\n",
    "# make sure the folder exists\n",
    "(Path(MODEL_PATH).parent).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the trained model (this line is unchanged)\n",
    "\n",
    "# CHANGED TO TEMP PATH, REPLACE WITH MODEL_PATH LATER\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Saved model to\", MODEL_PATH)\n",
    "\n",
    "# pickle the scaler, feature names, AND calibration stats\n",
    "\n",
    "# REPLACE WITH MODEL_PATH\n",
    "with open(MODEL_PATH, \"wb\") as f:\n",
    "    # channels list we used for X is:\n",
    "    feature_names = [f\"s{i}\" for i in range(1, NUM_EMG_SENSORS + 1)] + [\"quat_w\", \"quat_x\", \"quat_y\", \"quat_z\"]\n",
    "    # <<< Save all three items in a tuple >>>\n",
    "    try:\n",
    "        pickle.dump((scaler, feature_names, calibration_mean, calibration_std), f)\n",
    "\n",
    "        # REPLACE WITH METADATA_PATH\n",
    "        print(\"Saved metadata (scaler, features, calib_mean, calib_std) to\", METADATA_PATH)\n",
    "    except NameError:\n",
    "        print(\"ERROR: Could not save metadata. Was calibration_mean/std calculated earlier?\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saving metadata: {e}\")\n",
    "\n",
    "\n",
    "# --- END OF MODIFIED CELL 8 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_INPUT_PATH -> data\n",
      "  contains: ['artemis_archive', 'convert_old_data.py', 'physio_emg_imu_data_20250429_001144.csv', 'physio_emg_imu_data_20250429_174128.csv', 'physio_emg_imu_data_20250429_175521.csv', 'physio_emg_imu_data_20250430_002614.csv']\n",
      "\n",
      "MODEL_INPUT_PATH -> model\n",
      "  contains: ['artemis_archive', 'physio_metadata.pkl', 'physio_model.h5']\n",
      "\n",
      "MODEL_PATH       -> model\\physio_model.h5 exists? True\n",
      "METADATA_PATH    -> model\\physio_metadata.pkl exists? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from constants import DATA_INPUT_PATH, MODEL_INPUT_PATH, MODEL_PATH, METADATA_PATH\n",
    "\n",
    "print(\"DATA_INPUT_PATH ->\", DATA_INPUT_PATH)\n",
    "print(\"  contains:\", os.listdir(DATA_INPUT_PATH))\n",
    "print()\n",
    "print(\"MODEL_INPUT_PATH ->\", MODEL_INPUT_PATH)\n",
    "print(\"  contains:\", os.listdir(MODEL_INPUT_PATH))\n",
    "print()\n",
    "print(\"MODEL_PATH       ->\", MODEL_PATH, \"exists?\", os.path.exists(MODEL_PATH))\n",
    "print(\"METADATA_PATH    ->\", METADATA_PATH, \"exists?\", os.path.exists(METADATA_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blacb\\Documents\\GitHub\\NeuroSyn\\model-v4\\constants.py\n"
     ]
    }
   ],
   "source": [
    "import constants\n",
    "print(constants.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo results:\n",
      " • True:  0 Rest              → Predicted:  0 Rest\n",
      " • True:  1 Wrist Flexion     → Predicted:  1 Wrist Flexion\n",
      " • True:  2 Wrist Extension   → Predicted:  2 Wrist Extension\n",
      " • True:  3 Elbow Flexion     → Predicted:  2 Wrist Extension\n",
      " • True:  4 Elbow Extension   → Predicted:  3 Elbow Flexion\n",
      " • True:  5 Hand Close        → Predicted:  5 Hand Close\n",
      " • True:  6 Hand Open         → Predicted:  6 Hand Open\n",
      " • True:  7 Forearm Pronation → Predicted:  7 Forearm Pronation\n",
      " • True:  8 Forearm Supination → Predicted:  8 Forearm Supination\n",
      "\n",
      "Demo accuracy (RMS‐window per class): 78%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "from constants import DATA_INPUT_PATH, MODEL_PATH, METADATA_PATH, CLASSES, WINDOW_SIZE\n",
    "\n",
    "# — 1) load the freshest CSV —\n",
    "data_dir = Path(DATA_INPUT_PATH)\n",
    "csv_path = max(data_dir.glob(\"*.csv\"), key=lambda p: p.stat().st_mtime)\n",
    "df      = pd.read_csv(csv_path)\n",
    "\n",
    "# — 2) load scaler + feature names —\n",
    "with open(METADATA_PATH, \"rb\") as f:\n",
    "    scaler, feature_names, calibration_mean, calibration_std = pickle.load(f)\n",
    "\n",
    "# — 3) load your trained model —\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# — 4) for each class, grab the first 100 consecutive rows of that gesture,\n",
    "#         compute the 12-dim RMS feature vector, and predict —\n",
    "demo_rows = []\n",
    "for gid, name in CLASSES.items():\n",
    "    sub = df[df[\"gesture_id\"] == gid]\n",
    "    if len(sub) < WINDOW_SIZE:\n",
    "        print(f\"⚠️  not enough samples for '{name}' (need {WINDOW_SIZE}, got {len(sub)})\")\n",
    "        continue\n",
    "    \n",
    "    window  = sub[feature_names].values[:WINDOW_SIZE]\n",
    "    # Separate EMG/IMU parts from the 'window' variable\n",
    "    emg_part = window[:, :NUM_EMG_SENSORS]\n",
    "    imu_part = window[:, NUM_EMG_SENSORS:]\n",
    "\n",
    "    # Apply Z-score normalization to EMG part using LOADED stats\n",
    "    # (Make sure calibration_mean and calibration_std were loaded correctly earlier in this cell)\n",
    "    try:\n",
    "        normalized_emg_part = (emg_part - calibration_mean) / calibration_std\n",
    "    except NameError:\n",
    "        print(f\"ERROR: calibration_mean/std not available for demo processing (Class {gid}). Skipping.\")\n",
    "        continue # Skip to the next class if stats are missing\n",
    "\n",
    "    # Calculate RMS on normalized EMG and raw IMU\n",
    "    rms_emg = np.sqrt(np.mean(normalized_emg_part**2, axis=0))\n",
    "    rms_imu = np.sqrt(np.mean(imu_part**2, axis=0))\n",
    "\n",
    "    # Concatenate to get the final feature vector for the demo window\n",
    "    rms_vec = np.concatenate([rms_emg, rms_imu])\n",
    "\n",
    "    demo_rows.append((gid, name, rms_vec))\n",
    "\n",
    "# assemble our demo set\n",
    "y_true = [gid for gid,_,_ in demo_rows]\n",
    "X_demo = np.vstack([vec for *_, vec in demo_rows])\n",
    "\n",
    "# — 5) scale & predict —\n",
    "X_scaled = scaler.transform(X_demo)\n",
    "preds     = model.predict(X_scaled, verbose=0)\n",
    "pred_ids  = preds.argmax(axis=1)\n",
    "\n",
    "# — 6) report —\n",
    "print(\"Demo results:\")\n",
    "for (true_id, true_name, _), pred in zip(demo_rows, pred_ids):\n",
    "    print(f\" • True: {true_id:2d} {true_name:17s} → Predicted: {pred:2d} {CLASSES[pred]}\")\n",
    "    \n",
    "acc = np.mean(np.array(pred_ids) == np.array(y_true))\n",
    "print(f\"\\nDemo accuracy (RMS‐window per class): {acc:.0%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
