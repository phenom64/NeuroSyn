{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.4)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydot) (3.1.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\blacb\\appdata\\roaming\\python\\python312\\site-packages (2.17.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.1 in c:\\users\\blacb\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\blacb\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\blacb\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\blacb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pydot\n",
    "%pip install tensorflow\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import (\n",
    "    DATA_INPUT_PATH,\n",
    "    MODEL_PATH,\n",
    "    METADATA_PATH,\n",
    ")\n",
    "\n",
    "from constants import CLASSES\n",
    "num_classes = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the files in the data dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .csv(s) to dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in: C:\\Users\\blacb\\Documents\\GitHub\\NeuroSyn\\model-v4\\dataTemp\n",
      "Found CSVs: [WindowsPath('C:/Users/blacb/Documents/GitHub/NeuroSyn/model-v4/dataTemp/physio_emg_imu_data_20250430_002614.csv')]\n",
      "Shape before dropping duplicates: (10523, 88)\n",
      "Shape after dropping duplicates: (10523, 88)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Set your input path\n",
    "DATA_INPUT_PATH = Path(DATA_INPUT_PATH)  # ← safer path format\n",
    "\n",
    "# Find CSV files\n",
    "files = list(DATA_INPUT_PATH.glob(\"*.csv\"))\n",
    "print(\"Looking in:\", DATA_INPUT_PATH)\n",
    "print(\"Found CSVs:\", files)\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No CSV files found in {DATA_INPUT_PATH.resolve()}\")\n",
    "\n",
    "# Read all files\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "df = pd.concat(dfs, axis=0)\n",
    "\n",
    "# Reorder/select columns (if applicable)\n",
    "\n",
    "# Remove duplicates\n",
    "print(f\"Shape before dropping duplicates: {df.shape}\")\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: All column names after cleanup:\n",
      "['id', 'time', 'gesture_id', 'gesture_name', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 'quat_w', 'quatx', 'quaty', 'quatz', 'Wrist_x', 'Wrist_y', 'Wrist_z', 'Thumb_CMC_x', 'Thumb_CMC_y', 'Thumb_CMC_z', 'Thumb_MCP_x', 'Thumb_MCP_y', 'Thumb_MCP_z', 'Thumb_IP_x', 'Thumb_IP_y', 'Thumb_IP_z', 'Thumb_Tip_x', 'Thumb_Tip_y', 'Thumb_Tip_z', 'Index_MCP_x', 'Index_MCP_y', 'Index_MCP_z', 'Index_PIP_x', 'Index_PIP_y', 'Index_PIP_z', 'Index_DIP_x', 'Index_DIP_y', 'Index_DIP_z', 'Index_Tip_x', 'Index_Tip_y', 'Index_Tip_z', 'Middle_MCP_x', 'Middle_MCP_y', 'Middle_MCP_z', 'Middle_PIP_x', 'Middle_PIP_y', 'Middle_PIP_z', 'Middle_DIP_x', 'Middle_DIP_y', 'Middle_DIP_z', 'Middle_Tip_x', 'Middle_Tip_y', 'Middle_Tip_z', 'Ring_MCP_x', 'Ring_MCP_y', 'Ring_MCP_z', 'Ring_PIP_x', 'Ring_PIP_y', 'Ring_PIP_z', 'Ring_DIP_x', 'Ring_DIP_y', 'Ring_DIP_z', 'Ring_Tip_x', 'Ring_Tip_y', 'Ring_Tip_z', 'Pinky_MCP_x', 'Pinky_MCP_y', 'Pinky_MCP_z', 'Pinky_PIP_x', 'Pinky_PIP_y', 'Pinky_PIP_z', 'Pinky_DIP_x', 'Pinky_DIP_y', 'Pinky_DIP_z', 'Pinky_Tip_x', 'Pinky_Tip_y', 'Pinky_Tip_z', 'Shoulder_x', 'Shoulder_y', 'Shoulder_z', 'Elbow_x', 'Elbow_y', 'Elbow_z', 'Wrist2_x', 'Wrist2_y', 'Wrist2_z']\n",
      "Calculating calibration statistics from 'Rest' data...\n",
      "Landmark columns: ['Wrist_x', 'Wrist_y', 'Wrist_z', 'Thumb_CMC_x', 'Thumb_CMC_y', 'Thumb_CMC_z', 'Thumb_MCP_x', 'Thumb_MCP_y', 'Thumb_MCP_z', 'Thumb_IP_x', 'Thumb_IP_y', 'Thumb_IP_z', 'Thumb_Tip_x', 'Thumb_Tip_y', 'Thumb_Tip_z', 'Index_MCP_x', 'Index_MCP_y', 'Index_MCP_z', 'Index_PIP_x', 'Index_PIP_y', 'Index_PIP_z', 'Index_DIP_x', 'Index_DIP_y', 'Index_DIP_z', 'Index_Tip_x', 'Index_Tip_y', 'Index_Tip_z', 'Middle_MCP_x', 'Middle_MCP_y', 'Middle_MCP_z', 'Middle_PIP_x', 'Middle_PIP_y', 'Middle_PIP_z', 'Middle_DIP_x', 'Middle_DIP_y', 'Middle_DIP_z', 'Middle_Tip_x', 'Middle_Tip_y', 'Middle_Tip_z', 'Ring_MCP_x', 'Ring_MCP_y', 'Ring_MCP_z', 'Ring_PIP_x', 'Ring_PIP_y', 'Ring_PIP_z', 'Ring_DIP_x', 'Ring_DIP_y', 'Ring_DIP_z', 'Ring_Tip_x', 'Ring_Tip_y', 'Ring_Tip_z', 'Pinky_MCP_x', 'Pinky_MCP_y', 'Pinky_MCP_z', 'Pinky_PIP_x', 'Pinky_PIP_y', 'Pinky_PIP_z', 'Pinky_DIP_x', 'Pinky_DIP_y', 'Pinky_DIP_z', 'Pinky_Tip_x', 'Pinky_Tip_y', 'Pinky_Tip_z', 'Shoulder_x', 'Shoulder_y', 'Shoulder_z', 'Elbow_x', 'Elbow_y', 'Elbow_z', 'Wrist2_x', 'Wrist2_y', 'Wrist2_z']\n",
      "DEBUG: Found 72 landmark column names.\n",
      "Calculated Calibration Mean (shape (8,)):\n",
      "[ 24.05  22.07  23.42  24.56  48.45  40.27 125.8   30.23]\n",
      "Calculated Calibration StdDev (shape (8,)):\n",
      "[ 2.39  1.98  2.07  2.92 13.6  19.6  32.94  5.37]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from constants import NUM_EMG_SENSORS # Make sure NUM_EMG_SENSORS is defined (should be 8)\n",
    "\n",
    "# Assuming you load your data like this:\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# --- Add this line to clean up column names ---\n",
    "df.columns = df.columns.str.strip()\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Debug: Print all column names to verify\n",
    "print(\"DEBUG: All column names after cleanup:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "NUM_EMG_SENSORS = 8\n",
    "\n",
    "print(\"Calculating calibration statistics from 'Rest' data...\")\n",
    "\n",
    "# Select only the 'Rest' data (gesture_id == 0)\n",
    "rest_df = df[df['gesture_id'] == 0]\n",
    "\n",
    "# Select EMG columns (s1 to s8)\n",
    "emg_columns = [f\"s{i}\" for i in range(1, NUM_EMG_SENSORS + 1)]\n",
    "\n",
    "# Select IMU columns\n",
    "imu_columns = [\"quat_w\", \"quatx\", \"quaty\", \"quatz\"]\n",
    "\n",
    "# Define landmark column names\n",
    "landmark_column_names = [c for c in df.columns if c.endswith((\"_x\", \"_y\", \"_z\"))]\n",
    "\n",
    "# Debug: Print detected landmark columns\n",
    "print(f\"Landmark columns: {landmark_column_names}\")\n",
    "print(f\"DEBUG: Found {len(landmark_column_names)} landmark column names.\")\n",
    "\n",
    "# Check if the expected number of landmark columns (72) is found\n",
    "if len(landmark_column_names) != 72:\n",
    "    print(\"WARNING: Expected 72 landmark columns, but found\", len(landmark_column_names))\n",
    "    print(\"DEBUG: Found columns:\", landmark_column_names)\n",
    "    # Optionally raise an error\n",
    "    # raise ValueError(f\"Expected 72 landmark columns, found {len(landmark_column_names)}\")\n",
    "\n",
    "# Ensure rest data exists before calculating stats\n",
    "if 'gesture_id' in df.columns and 0 in df['gesture_id'].values:\n",
    "    rest_df = df[df['gesture_id'] == 0].copy()\n",
    "    rest_emg_data = rest_df[emg_columns].values\n",
    "\n",
    "    if len(rest_emg_data) > 0:\n",
    "        calibration_mean = np.mean(rest_emg_data, axis=0)\n",
    "        calibration_std = np.std(rest_emg_data, axis=0)\n",
    "        calibration_std[calibration_std < 1e-6] = 1.0\n",
    "\n",
    "        print(f\"Calculated Calibration Mean (shape {calibration_mean.shape}):\\n{np.round(calibration_mean, 2)}\")\n",
    "        print(f\"Calculated Calibration StdDev (shape {calibration_std.shape}):\\n{np.round(calibration_std, 2)}\")\n",
    "    else:\n",
    "        print(\"ERROR: No 'Rest' data rows found (gesture_id == 0)!\")\n",
    "        calibration_mean = np.zeros(NUM_EMG_SENSORS)\n",
    "        calibration_std = np.ones(NUM_EMG_SENSORS)\n",
    "        print(\"Using default calibration stats (mean=0, std=1). CHECK YOUR DATA.\")\n",
    "else:\n",
    "    print(\"ERROR: 'gesture_id' column missing or no 'Rest' data found.\")\n",
    "    calibration_mean = np.zeros(NUM_EMG_SENSORS)\n",
    "    calibration_std = np.ones(NUM_EMG_SENSORS)\n",
    "    print(\"Using default calibration stats (mean=0, std=1). CHECK YOUR DATA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature extraction and landmark target creation...\n",
      "names:         Wrist_x   Wrist_y       Wrist_z  Thumb_CMC_x  Thumb_CMC_y  \\\n",
      "0      0.501415  0.497794  2.854314e-07     0.448627     0.461873   \n",
      "1      0.499809  0.495536  2.839110e-07     0.448270     0.460057   \n",
      "2      0.501324  0.502592  2.867195e-07     0.448728     0.465319   \n",
      "3      0.501258  0.506695  2.854746e-07     0.450308     0.469425   \n",
      "4      0.501871  0.506546  2.945126e-07     0.450076     0.467540   \n",
      "...         ...       ...           ...          ...          ...   \n",
      "10518  0.502680  0.503380  2.788704e-07     0.451335     0.465506   \n",
      "10519  0.502589  0.502521  2.797877e-07     0.451682     0.464579   \n",
      "10520  0.503018  0.504544  2.750186e-07     0.451561     0.465724   \n",
      "10521  0.503794  0.503255  2.858833e-07     0.452157     0.465333   \n",
      "10522  0.505278  0.504900  2.815112e-07     0.453410     0.466702   \n",
      "\n",
      "       Thumb_CMC_z  Thumb_MCP_x  Thumb_MCP_y  Thumb_MCP_z  Thumb_IP_x  ...  \\\n",
      "0        -0.013308     0.405460     0.392858    -0.017696    0.378812  ...   \n",
      "1        -0.013726     0.405945     0.392639    -0.018565    0.380150  ...   \n",
      "2        -0.013533     0.406795     0.396512    -0.019119    0.381100  ...   \n",
      "3        -0.013032     0.408618     0.400846    -0.018093    0.383271  ...   \n",
      "4        -0.013058     0.408698     0.398822    -0.018672    0.383675  ...   \n",
      "...            ...          ...          ...          ...         ...  ...   \n",
      "10518    -0.013001     0.411895     0.396774    -0.018547    0.388622  ...   \n",
      "10519    -0.012558     0.411874     0.396562    -0.017563    0.388708  ...   \n",
      "10520    -0.011943     0.412350     0.396799    -0.016442    0.389506  ...   \n",
      "10521    -0.013374     0.412937     0.397232    -0.018841    0.389839  ...   \n",
      "10522    -0.012964     0.413333     0.397172    -0.018056    0.389811  ...   \n",
      "\n",
      "       Pinky_Tip_z  Shoulder_x  Shoulder_y  Shoulder_z  Elbow_x   Elbow_y  \\\n",
      "0        -0.056201     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "1        -0.059424     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "2        -0.061875     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "3        -0.062121     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "4        -0.061694     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "...            ...         ...         ...         ...      ...       ...   \n",
      "10518    -0.063697     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "10519    -0.061180     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "10520    -0.060791     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "10521    -0.062557     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "10522    -0.061713     0.32029    0.232342    0.982352  0.32029  0.232342   \n",
      "\n",
      "        Elbow_z  Wrist2_x  Wrist2_y  Wrist2_z  \n",
      "0      0.982352   0.32029  0.232342  0.982352  \n",
      "1      0.982352   0.32029  0.232342  0.982352  \n",
      "2      0.982352   0.32029  0.232342  0.982352  \n",
      "3      0.982352   0.32029  0.232342  0.982352  \n",
      "4      0.982352   0.32029  0.232342  0.982352  \n",
      "...         ...       ...       ...       ...  \n",
      "10518  0.982352   0.32029  0.232342  0.982352  \n",
      "10519  0.982352   0.32029  0.232342  0.982352  \n",
      "10520  0.982352   0.32029  0.232342  0.982352  \n",
      "10521  0.982352   0.32029  0.232342  0.982352  \n",
      "10522  0.982352   0.32029  0.232342  0.982352  \n",
      "\n",
      "[10523 rows x 72 columns]\n",
      "Processed 420 windows.\n",
      "X shape (RMS features): (420, 12)\n",
      "Y shape (Landmark targets): (420, 72)\n"
     ]
    }
   ],
   "source": [
    "# --- MODIFIED CELL 5: Sliding-window Feature Extraction with Z-Score ---\n",
    "import numpy as np\n",
    "from constants import WINDOW_SIZE, WINDOW_STEP, NUM_EMG_SENSORS # Added NUM_EMG_SENSORS\n",
    "\n",
    "# CELL 2 (Corrected)\n",
    "# --- MODIFIED CELL: Sliding-window Feature Extraction & Target Creation ---\n",
    "import numpy as np\n",
    "# Assuming constants WINDOW_SIZE, WINDOW_STEP, NUM_EMG_SENSORS are defined\n",
    "# Assuming calibration_mean, calibration_std from CELL 1 exist\n",
    "# Assuming landmark_column_names from CELL 1 exists\n",
    "# Assuming df is your loaded DataFrame\n",
    "\n",
    "# define a real scaler object\n",
    "scaler = StandardScaler()\n",
    "scaler.mean_, scaler.scale_ = calibration_mean, calibration_std\n",
    "\n",
    "print(\"Starting feature extraction and landmark target creation...\")\n",
    "\n",
    "# Select EMG+IMU columns for features\n",
    "feature_channels = [f\"s{i}\" for i in range(1, NUM_EMG_SENSORS + 1)] + [\"quat_w\", \"quatx\", \"quaty\", \"quatz\"]\n",
    "raw_features = df[feature_channels].values      # shape = [total_samples, 12]\n",
    "\n",
    "# Select landmark columns for targets using the list from CELL 1\n",
    "# Check if landmark_column_names actually exists and is not empty\n",
    "if 'landmark_column_names' not in globals() or not landmark_column_names:\n",
    "     raise NameError(\"landmark_column_names is not defined or empty. Ensure CELL 1 ran correctly and found columns.\")\n",
    "if len(landmark_column_names) != 72:\n",
    "     print(f\"WARNING: Proceeding with {len(landmark_column_names)} landmark columns, but model expects 72. Error is likely.\")\n",
    "     # Or raise ValueError(\"Incorrect number of landmark columns found.\")\n",
    "\n",
    "\n",
    "\n",
    "raw_landmarks = df[landmark_column_names].values # shape = [total_samples, num_landmark_columns (hopefully 72)]\n",
    "\n",
    "print(f\"names: {df[landmark_column_names]}\")\n",
    "\n",
    "X, Y = [], [] # Uppercase Y for landmark targets\n",
    "num_windows = 0\n",
    "\n",
    "for start in range(0, len(raw_features) - WINDOW_SIZE + 1, WINDOW_STEP):\n",
    "    num_windows += 1\n",
    "    window_features = raw_features[start : start + WINDOW_SIZE] # shape = [WINDOW_SIZE, 12]\n",
    "\n",
    "    # Separate EMG and IMU parts of the window\n",
    "    emg_part = window_features[:, :NUM_EMG_SENSORS]   # shape = [WINDOW_SIZE, 8]\n",
    "    imu_part = window_features[:, NUM_EMG_SENSORS:]   # shape = [WINDOW_SIZE, 4]\n",
    "\n",
    "    # Apply Z-score normalization to EMG part\n",
    "    try:\n",
    "        normalized_emg_part = (emg_part - calibration_mean) / calibration_std\n",
    "    except NameError:\n",
    "        print(\"ERROR: calibration_mean or calibration_std not defined. Make sure CELL 1 was run.\")\n",
    "        break # Stop processing\n",
    "\n",
    "    # Calculate RMS on NORMALIZED EMG and ORIGINAL IMU\n",
    "    rms_emg = np.sqrt(np.mean(normalized_emg_part**2, axis=0))\n",
    "    rms_imu = np.sqrt(np.mean(imu_part**2, axis=0))\n",
    "\n",
    "    # Concatenate features\n",
    "    rms_feat = np.concatenate([rms_emg, rms_imu])\n",
    "    X.append(rms_feat)\n",
    "\n",
    "    # Assign the window’s “center” LANDMARK data as the target\n",
    "    center_idx = start + WINDOW_SIZE // 2\n",
    "    Y.append(raw_landmarks[center_idx]) # <-- Append the landmark row (should have 72 values)\n",
    "\n",
    "X = np.array(X)  # shape = [n_windows, 12]\n",
    "Y = np.array(Y)  # shape = [n_windows, 72] <-- Should now have 72 columns\n",
    "\n",
    "print(f\"Processed {num_windows} windows.\")\n",
    "print(\"X shape (RMS features):\", X.shape)\n",
    "print(\"Y shape (Landmark targets):\", Y.shape) # <-- Verify this shows (..., 72)\n",
    "\n",
    "# Check Y shape explicitly\n",
    "if Y.shape[1] != 72:\n",
    "    print(f\"ERROR: Y shape is {Y.shape}, expected second dimension to be 72.\")\n",
    "    print(\"       Check the landmark columns in your CSV and CELL 1.\")\n",
    "\n",
    "# --- END OF CORRECTED CELL 2 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, split, and one-shot encode RMS feature windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (252, 12) (252, 72)\n",
      "Val:   (84, 12) (84, 72)\n",
      "Test:  (84, 12) (84, 72)\n"
     ]
    }
   ],
   "source": [
    "# CELL 3 (Should now work correctly if Y from CELL 2 is shape [?, 72])\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) train+val vs test\n",
    "X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.20, random_state=42 # Using X and Y from Corrected CELL 2\n",
    ")\n",
    "# 2) train vs val\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_trainval, Y_trainval, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, Y_train.shape) # Y_train shape should be [?, 72]\n",
    "print(\"Val:  \", X_val.shape,   Y_val.shape)  # Y_val shape should be [?, 72]\n",
    "print(\"Test: \", X_test.shape,  Y_test.shape) # Y_test shape should be [?, 72]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, compile & train a simple dense classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blacb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.6793 - mae: 0.6150 - val_loss: 2.3702 - val_mae: 0.9842\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5421 - mae: 0.5523 - val_loss: 0.9929 - val_mae: 0.6668\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4576 - mae: 0.5079 - val_loss: 0.5276 - val_mae: 0.5084\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3486 - mae: 0.4454 - val_loss: 0.3378 - val_mae: 0.4219\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3036 - mae: 0.4222 - val_loss: 0.2527 - val_mae: 0.3736\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2908 - mae: 0.4090 - val_loss: 0.2048 - val_mae: 0.3424\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2443 - mae: 0.3753 - val_loss: 0.1756 - val_mae: 0.3210\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2239 - mae: 0.3587 - val_loss: 0.1552 - val_mae: 0.3040\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2019 - mae: 0.3418 - val_loss: 0.1395 - val_mae: 0.2898\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1771 - mae: 0.3205 - val_loss: 0.1279 - val_mae: 0.2781\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1586 - mae: 0.3057 - val_loss: 0.1185 - val_mae: 0.2678\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1503 - mae: 0.2964 - val_loss: 0.1113 - val_mae: 0.2593\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1369 - mae: 0.2841 - val_loss: 0.1057 - val_mae: 0.2524\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1310 - mae: 0.2749 - val_loss: 0.1004 - val_mae: 0.2457\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1289 - mae: 0.2711 - val_loss: 0.0954 - val_mae: 0.2392\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1153 - mae: 0.2589 - val_loss: 0.0911 - val_mae: 0.2334\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1088 - mae: 0.2515 - val_loss: 0.0873 - val_mae: 0.2280\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1123 - mae: 0.2529 - val_loss: 0.0841 - val_mae: 0.2233\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0948 - mae: 0.2350 - val_loss: 0.0812 - val_mae: 0.2189\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0982 - mae: 0.2351 - val_loss: 0.0782 - val_mae: 0.2144\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0921 - mae: 0.2291 - val_loss: 0.0753 - val_mae: 0.2100\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0847 - mae: 0.2232 - val_loss: 0.0727 - val_mae: 0.2059\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0787 - mae: 0.2137 - val_loss: 0.0703 - val_mae: 0.2022\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0778 - mae: 0.2137 - val_loss: 0.0682 - val_mae: 0.1985\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0762 - mae: 0.2106 - val_loss: 0.0662 - val_mae: 0.1950\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0760 - mae: 0.2105 - val_loss: 0.0643 - val_mae: 0.1916\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0699 - mae: 0.2012 - val_loss: 0.0622 - val_mae: 0.1879\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0666 - mae: 0.1959 - val_loss: 0.0605 - val_mae: 0.1850\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0667 - mae: 0.1973 - val_loss: 0.0588 - val_mae: 0.1820\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0603 - mae: 0.1852 - val_loss: 0.0571 - val_mae: 0.1792\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0654 - mae: 0.1948 - val_loss: 0.0555 - val_mae: 0.1766\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0582 - mae: 0.1852 - val_loss: 0.0538 - val_mae: 0.1736\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0561 - mae: 0.1815 - val_loss: 0.0523 - val_mae: 0.1711\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0543 - mae: 0.1778 - val_loss: 0.0509 - val_mae: 0.1690\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0511 - mae: 0.1723 - val_loss: 0.0497 - val_mae: 0.1669\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0550 - mae: 0.1737 - val_loss: 0.0484 - val_mae: 0.1646\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0467 - mae: 0.1638 - val_loss: 0.0471 - val_mae: 0.1620\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0460 - mae: 0.1638 - val_loss: 0.0457 - val_mae: 0.1591\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0459 - mae: 0.1621 - val_loss: 0.0440 - val_mae: 0.1556\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0444 - mae: 0.1576 - val_loss: 0.0422 - val_mae: 0.1519\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0443 - mae: 0.1608 - val_loss: 0.0406 - val_mae: 0.1482\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0407 - mae: 0.1527 - val_loss: 0.0392 - val_mae: 0.1450\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0376 - mae: 0.1470 - val_loss: 0.0379 - val_mae: 0.1420\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0408 - mae: 0.1500 - val_loss: 0.0366 - val_mae: 0.1394\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0415 - mae: 0.1491 - val_loss: 0.0353 - val_mae: 0.1367\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0355 - mae: 0.1427 - val_loss: 0.0345 - val_mae: 0.1349\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0337 - mae: 0.1390 - val_loss: 0.0335 - val_mae: 0.1327\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0394 - mae: 0.1502 - val_loss: 0.0326 - val_mae: 0.1305\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0354 - mae: 0.1394 - val_loss: 0.0316 - val_mae: 0.1281\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0307 - mae: 0.1322 - val_loss: 0.0307 - val_mae: 0.1260\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0329 - mae: 0.1355 - val_loss: 0.0298 - val_mae: 0.1238\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0307 - mae: 0.1310 - val_loss: 0.0288 - val_mae: 0.1213\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0281 - mae: 0.1257 - val_loss: 0.0279 - val_mae: 0.1194\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0315 - mae: 0.1310 - val_loss: 0.0272 - val_mae: 0.1176\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0281 - mae: 0.1267 - val_loss: 0.0263 - val_mae: 0.1156\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0301 - mae: 0.1289 - val_loss: 0.0257 - val_mae: 0.1145\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0293 - mae: 0.1258 - val_loss: 0.0251 - val_mae: 0.1128\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0267 - mae: 0.1216 - val_loss: 0.0247 - val_mae: 0.1112\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0258 - mae: 0.1189 - val_loss: 0.0244 - val_mae: 0.1103\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0234 - mae: 0.1144 - val_loss: 0.0240 - val_mae: 0.1091\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0231 - mae: 0.1137 - val_loss: 0.0235 - val_mae: 0.1077\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0248 - mae: 0.1155 - val_loss: 0.0233 - val_mae: 0.1068\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0235 - mae: 0.1135 - val_loss: 0.0228 - val_mae: 0.1053\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0242 - mae: 0.1137 - val_loss: 0.0225 - val_mae: 0.1042\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0229 - mae: 0.1099 - val_loss: 0.0220 - val_mae: 0.1030\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0237 - mae: 0.1136 - val_loss: 0.0215 - val_mae: 0.1018\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0217 - mae: 0.1070 - val_loss: 0.0209 - val_mae: 0.1003\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0220 - mae: 0.1084 - val_loss: 0.0202 - val_mae: 0.0985\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0193 - mae: 0.1029 - val_loss: 0.0195 - val_mae: 0.0967\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0206 - mae: 0.1055 - val_loss: 0.0188 - val_mae: 0.0948\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0182 - mae: 0.0997 - val_loss: 0.0180 - val_mae: 0.0928\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0187 - mae: 0.1003 - val_loss: 0.0170 - val_mae: 0.0902\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0203 - mae: 0.1047 - val_loss: 0.0162 - val_mae: 0.0880\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0185 - mae: 0.1003 - val_loss: 0.0154 - val_mae: 0.0861\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0177 - mae: 0.0973 - val_loss: 0.0148 - val_mae: 0.0847\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0177 - mae: 0.0958 - val_loss: 0.0143 - val_mae: 0.0836\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0172 - mae: 0.0966 - val_loss: 0.0139 - val_mae: 0.0826\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0177 - mae: 0.0980 - val_loss: 0.0138 - val_mae: 0.0823\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0163 - mae: 0.0936 - val_loss: 0.0138 - val_mae: 0.0824\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0194 - mae: 0.0970 - val_loss: 0.0141 - val_mae: 0.0823\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0165 - mae: 0.0936 - val_loss: 0.0141 - val_mae: 0.0813\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0184 - mae: 0.0967 - val_loss: 0.0139 - val_mae: 0.0800\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0789 \n",
      "Final test MSE: 0.0114, MAE: 0.0766\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(72, activation=\"linear\") # 72 = 63 (hands) + 9 (shoulder elbow wrist)\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# fit with explicit validation_data\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=3, restore_best_weights=True\n",
    "    )]\n",
    ")\n",
    "\n",
    "test_mse, test_mae = model.evaluate(X_test, Y_test)\n",
    "print(f\"Final test MSE: {test_mse:.4f}, MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model and the scalar + feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to model\\physio_model.h5\n",
      "Saved metadata (scaler, features, calib_mean, calib_std) to model-v4\\model_temp\\physio_temp_meta.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- MODIFIED CELL 8: Save Model and Metadata ---\n",
    "# make sure the folder exists\n",
    "(Path(MODEL_PATH).parent).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the trained model (this line is unchanged)\n",
    "\n",
    "# CHANGED TO TEMP PATH, REPLACE WITH MODEL_PATH LATER\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Saved model to\", MODEL_PATH)\n",
    "\n",
    "# pickle the scaler, feature names, AND calibration stats\n",
    "\n",
    "with open(MODEL_PATH, \"wb\") as f:\n",
    "    # channels list we used for X is:\n",
    "    feature_names = [f\"s{i}\" for i in range(1, NUM_EMG_SENSORS + 1)] + [\"quat_w\", \"quat_x\", \"quat_y\", \"quat_z\"]\n",
    "    # <<< Save all three items in a tuple >>>\n",
    "    try:\n",
    "        pickle.dump((scaler, feature_names, calibration_mean, calibration_std), f)\n",
    "\n",
    "        # REPLACE WITH METADATA_PATH\n",
    "        print(\"Saved metadata (scaler, features, calib_mean, calib_std) to\", METADATA_PATH)\n",
    "    except NameError:\n",
    "        print(\"ERROR: Could not save metadata. Was calibration_mean/std calculated earlier?\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saving metadata: {e}\")\n",
    "\n",
    "\n",
    "# --- END OF MODIFIED CELL 8 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_INPUT_PATH -> data\n",
      "  contains: ['artemis_archive', 'convert_old_data.py', 'physio_emg_imu_data_20250429_001144.csv', 'physio_emg_imu_data_20250429_174128.csv', 'physio_emg_imu_data_20250429_175521.csv', 'physio_emg_imu_data_20250430_002614.csv']\n",
      "\n",
      "MODEL_INPUT_PATH -> model\n",
      "  contains: ['artemis_archive', 'physio_metadata.pkl', 'physio_model.h5']\n",
      "\n",
      "MODEL_PATH       -> model\\physio_model.h5 exists? True\n",
      "METADATA_PATH    -> model\\physio_metadata.pkl exists? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from constants import DATA_INPUT_PATH, MODEL_INPUT_PATH, MODEL_PATH, METADATA_PATH\n",
    "\n",
    "print(\"DATA_INPUT_PATH ->\", DATA_INPUT_PATH)\n",
    "print(\"  contains:\", os.listdir(DATA_INPUT_PATH))\n",
    "print()\n",
    "print(\"MODEL_INPUT_PATH ->\", MODEL_INPUT_PATH)\n",
    "print(\"  contains:\", os.listdir(MODEL_INPUT_PATH))\n",
    "print()\n",
    "print(\"MODEL_PATH       ->\", MODEL_PATH, \"exists?\", os.path.exists(MODEL_PATH))\n",
    "print(\"METADATA_PATH    ->\", METADATA_PATH, \"exists?\", os.path.exists(METADATA_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blacb\\Documents\\GitHub\\NeuroSyn\\model-v4\\constants.py\n"
     ]
    }
   ],
   "source": [
    "import constants\n",
    "print(constants.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo results:\n",
      " • True:  0 Rest              → Predicted:  0 Rest\n",
      " • True:  1 Wrist Flexion     → Predicted:  1 Wrist Flexion\n",
      " • True:  2 Wrist Extension   → Predicted:  2 Wrist Extension\n",
      " • True:  3 Elbow Flexion     → Predicted:  2 Wrist Extension\n",
      " • True:  4 Elbow Extension   → Predicted:  3 Elbow Flexion\n",
      " • True:  5 Hand Close        → Predicted:  5 Hand Close\n",
      " • True:  6 Hand Open         → Predicted:  6 Hand Open\n",
      " • True:  7 Forearm Pronation → Predicted:  7 Forearm Pronation\n",
      " • True:  8 Forearm Supination → Predicted:  8 Forearm Supination\n",
      "\n",
      "Demo accuracy (RMS‐window per class): 78%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "from constants import DATA_INPUT_PATH, MODEL_PATH, METADATA_PATH, CLASSES, WINDOW_SIZE\n",
    "\n",
    "# — 1) load the freshest CSV —\n",
    "data_dir = Path(DATA_INPUT_PATH)\n",
    "csv_path = max(data_dir.glob(\"*.csv\"), key=lambda p: p.stat().st_mtime)\n",
    "df      = pd.read_csv(csv_path)\n",
    "\n",
    "# — 2) load scaler + feature names —\n",
    "with open(METADATA_PATH, \"rb\") as f:\n",
    "    scaler, feature_names, calibration_mean, calibration_std = pickle.load(f)\n",
    "\n",
    "# — 3) load your trained model —\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# — 4) for each class, grab the first 100 consecutive rows of that gesture,\n",
    "#         compute the 12-dim RMS feature vector, and predict —\n",
    "demo_rows = []\n",
    "for gid, name in CLASSES.items():\n",
    "    sub = df[df[\"gesture_id\"] == gid]\n",
    "    if len(sub) < WINDOW_SIZE:\n",
    "        print(f\"⚠️  not enough samples for '{name}' (need {WINDOW_SIZE}, got {len(sub)})\")\n",
    "        continue\n",
    "    \n",
    "    window  = sub[feature_names].values[:WINDOW_SIZE]\n",
    "    # Separate EMG/IMU parts from the 'window' variable\n",
    "    emg_part = window[:, :NUM_EMG_SENSORS]\n",
    "    imu_part = window[:, NUM_EMG_SENSORS:]\n",
    "\n",
    "    # Apply Z-score normalization to EMG part using LOADED stats\n",
    "    # (Make sure calibration_mean and calibration_std were loaded correctly earlier in this cell)\n",
    "    try:\n",
    "        normalized_emg_part = (emg_part - calibration_mean) / calibration_std\n",
    "    except NameError:\n",
    "        print(f\"ERROR: calibration_mean/std not available for demo processing (Class {gid}). Skipping.\")\n",
    "        continue # Skip to the next class if stats are missing\n",
    "\n",
    "    # Calculate RMS on normalized EMG and raw IMU\n",
    "    rms_emg = np.sqrt(np.mean(normalized_emg_part**2, axis=0))\n",
    "    rms_imu = np.sqrt(np.mean(imu_part**2, axis=0))\n",
    "\n",
    "    # Concatenate to get the final feature vector for the demo window\n",
    "    rms_vec = np.concatenate([rms_emg, rms_imu])\n",
    "\n",
    "    demo_rows.append((gid, name, rms_vec))\n",
    "\n",
    "# assemble our demo set\n",
    "y_true = [gid for gid,_,_ in demo_rows]\n",
    "X_demo = np.vstack([vec for *_, vec in demo_rows])\n",
    "\n",
    "# — 5) scale & predict —\n",
    "X_scaled = scaler.transform(X_demo)\n",
    "preds     = model.predict(X_scaled, verbose=0)\n",
    "pred_ids  = preds.argmax(axis=1)\n",
    "\n",
    "# — 6) report —\n",
    "print(\"Demo results:\")\n",
    "for (true_id, true_name, _), pred in zip(demo_rows, pred_ids):\n",
    "    print(f\" • True: {true_id:2d} {true_name:17s} → Predicted: {pred:2d} {CLASSES[pred]}\")\n",
    "    \n",
    "acc = np.mean(np.array(pred_ids) == np.array(y_true))\n",
    "print(f\"\\nDemo accuracy (RMS‐window per class): {acc:.0%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
