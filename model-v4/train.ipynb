{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydot\n",
    "%pip install tensorflow\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NeuroSyn Physio Constants Loaded (v3 - Compatibility Names) ---\n",
      "Myo Address: DD:31:D8:40:BC:22\n",
      "Data Input Path: model-v4\\data\n",
      "Model Path: model\\physio_model.h5\n",
      "Metadata Path: model\\physio_metadata.pkl\n",
      "Collection Time per Rep (s): 5\n",
      "Repetitions per Exercise: 5\n",
      "Number of Classes: 9\n",
      "Classes Map: {0: 'Rest', 1: 'Wrist Flexion', 2: 'Wrist Extension', 3: 'Elbow Flexion', 4: 'Elbow Extension', 5: 'Hand Close', 6: 'Hand Open', 7: 'Forearm Pronation', 8: 'Forearm Supination'}\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import (\n",
    "    DATA_INPUT_PATH,\n",
    "    MODEL_PATH,\n",
    "    METADATA_PATH,\n",
    ")\n",
    "\n",
    "from constants import CLASSES\n",
    "num_classes = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the files in the data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('data/physio_emg_imu_data_20250429_001144.csv'), WindowsPath('data/physio_emg_imu_data_20250429_174128.csv'), WindowsPath('data/physio_emg_imu_data_20250429_175521.csv'), WindowsPath('data/physio_emg_imu_data_20250430_002614.csv')]\n"
     ]
    }
   ],
   "source": [
    "# Read all of the files in the data folder\n",
    "files_in_folder = Path(DATA_INPUT_PATH).glob(\"*.csv\")\n",
    "\n",
    "files = [x for x in files_in_folder]\n",
    "print([file for file in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .csv(s) to dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in: data\n",
      "Found CSVs: [WindowsPath('data/physio_emg_imu_data_20250429_001144.csv'), WindowsPath('data/physio_emg_imu_data_20250429_174128.csv'), WindowsPath('data/physio_emg_imu_data_20250429_175521.csv'), WindowsPath('data/physio_emg_imu_data_20250430_002614.csv')]\n",
      "   gesture_id   s1   s2  s3  s4  s5  s6  s7   s8    quat_w    quat_x  \\\n",
      "0           0  320  214  81  41  38  26  26   69  0.875610  0.454102   \n",
      "1           0  347  217  81  36  36  28  31  115  0.875610  0.454102   \n",
      "2           0  224  131  55  37  35  27  28  116  0.875671  0.454041   \n",
      "3           0  207  114  51  35  31  27  31  122  0.875671  0.453918   \n",
      "4           0  182  100  45  37  30  27  30  118  0.875671  0.453979   \n",
      "\n",
      "     quat_y    quat_z  \n",
      "0 -0.153137 -0.059937  \n",
      "1 -0.153137 -0.059937  \n",
      "2 -0.153076 -0.059937  \n",
      "3 -0.153198 -0.059692  \n",
      "4 -0.153381 -0.059326  \n",
      "Shape of dataframe before removing duplicates (42037, 13)\n",
      "Shape of dataframe after removing duplicates (42037, 13)\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the files\n",
    "dfs = []\n",
    "print(\"Looking in:\", DATA_INPUT_PATH)\n",
    "print(\"Found CSVs:\", list(Path(DATA_INPUT_PATH).glob(\"*.csv\")))\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(str(file))\n",
    "    dfs.append(df)\n",
    "        \n",
    "# Convert the data to a DataFrame\n",
    "df = pd.concat([x for x in dfs], axis=0)\n",
    "\n",
    "# after concatenating dfs…\n",
    "columns = [\"gesture_id\"] \\\n",
    "        + [f\"s{i}\" for i in range(1,9)] \\\n",
    "        + [\"quat_w\",\"quat_x\",\"quat_y\",\"quat_z\"]\n",
    "df = df[columns]\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Before removing duplicates\n",
    "print(f\"Shape of dataframe before removing duplicates {df.shape}\")\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Shape of dataframe after removing duplicates {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (839, 12)\n",
      "y shape: (839,)\n"
     ]
    }
   ],
   "source": [
    "# --- 3) Sliding‐window RMS feature extraction ---\n",
    "import numpy as np\n",
    "from constants import WINDOW_SIZE, WINDOW_STEP\n",
    "\n",
    "# build channel list in correct order\n",
    "channels = [f\"s{i}\" for i in range(1,9)] + [\"quat_w\",\"quat_x\",\"quat_y\",\"quat_z\"]\n",
    "raw = df[channels].values          # shape = [total_samples, 12]\n",
    "labels = df[\"gesture_id\"].values   # shape = [total_samples,]\n",
    "\n",
    "X, y = [], []\n",
    "for start in range(0, len(raw) - WINDOW_SIZE + 1, WINDOW_STEP):\n",
    "    window = raw[start : start + WINDOW_SIZE]     # shape = [WINDOW_SIZE, 12]\n",
    "    rms_feat = np.sqrt(np.mean(window**2, axis=0))  # compute RMS per channel\n",
    "    X.append(rms_feat)\n",
    "    # assign the window’s “center” label\n",
    "    center_idx = start + WINDOW_SIZE//2\n",
    "    y.append(labels[center_idx])\n",
    "\n",
    "X = np.array(X)   # shape = [n_windows, 12]\n",
    "y = np.array(y)   # shape = [n_windows,]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, split, and one-shot encode RMS feature windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (671, 12)   y_train: (671, 9)\n",
      "X_test:  (168, 12)   y_test:  (168, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ---- scale features ----\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ---- one-hot labels ----\n",
    "y_cat = to_categorical(y, num_classes)\n",
    "\n",
    "# ---- train / test split ----\n",
    "# stratify=y ensures each class is proportionally represented\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_cat,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"  y_train:\", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape, \"  y_test: \",  y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, compile & train a simple dense classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavish Krishnakumar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1202 - loss: 2.9548 - val_accuracy: 0.2444 - val_loss: 2.1199\n",
      "Epoch 2/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1874 - loss: 2.3590 - val_accuracy: 0.3037 - val_loss: 2.0547\n",
      "Epoch 3/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2822 - loss: 1.9224 - val_accuracy: 0.4741 - val_loss: 1.9932\n",
      "Epoch 4/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3949 - loss: 1.7796 - val_accuracy: 0.5037 - val_loss: 1.9376\n",
      "Epoch 5/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4944 - loss: 1.5185 - val_accuracy: 0.5037 - val_loss: 1.8797\n",
      "Epoch 6/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5031 - loss: 1.4912 - val_accuracy: 0.5407 - val_loss: 1.8181\n",
      "Epoch 7/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5563 - loss: 1.3083 - val_accuracy: 0.6000 - val_loss: 1.7488\n",
      "Epoch 8/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6170 - loss: 1.1975 - val_accuracy: 0.6370 - val_loss: 1.6824\n",
      "Epoch 9/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6660 - loss: 1.0969 - val_accuracy: 0.6519 - val_loss: 1.6075\n",
      "Epoch 10/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6581 - loss: 1.0759 - val_accuracy: 0.6889 - val_loss: 1.5382\n",
      "Epoch 11/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6904 - loss: 1.0285 - val_accuracy: 0.7333 - val_loss: 1.4686\n",
      "Epoch 12/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7337 - loss: 0.9359 - val_accuracy: 0.7407 - val_loss: 1.3975\n",
      "Epoch 13/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7643 - loss: 0.8615 - val_accuracy: 0.7630 - val_loss: 1.3269\n",
      "Epoch 14/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7528 - loss: 0.8138 - val_accuracy: 0.7926 - val_loss: 1.2611\n",
      "Epoch 15/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7766 - loss: 0.7501 - val_accuracy: 0.8444 - val_loss: 1.1907\n",
      "Epoch 16/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7934 - loss: 0.6740 - val_accuracy: 0.8370 - val_loss: 1.1216\n",
      "Epoch 17/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8303 - loss: 0.6603 - val_accuracy: 0.8667 - val_loss: 1.0601\n",
      "Epoch 18/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8331 - loss: 0.6254 - val_accuracy: 0.8148 - val_loss: 1.0086\n",
      "Epoch 19/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 0.6338 - val_accuracy: 0.8519 - val_loss: 0.9493\n",
      "Epoch 20/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8502 - loss: 0.5561 - val_accuracy: 0.8815 - val_loss: 0.8899\n",
      "Epoch 21/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8262 - loss: 0.5684 - val_accuracy: 0.8667 - val_loss: 0.8327\n",
      "Epoch 22/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.5485 - val_accuracy: 0.8667 - val_loss: 0.7887\n",
      "Epoch 23/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8655 - loss: 0.4967 - val_accuracy: 0.8889 - val_loss: 0.7394\n",
      "Epoch 24/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8792 - loss: 0.4546 - val_accuracy: 0.9111 - val_loss: 0.6856\n",
      "Epoch 25/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8547 - loss: 0.4775 - val_accuracy: 0.8889 - val_loss: 0.6447\n",
      "Epoch 26/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8605 - loss: 0.4707 - val_accuracy: 0.8963 - val_loss: 0.6029\n",
      "Epoch 27/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8528 - loss: 0.4490 - val_accuracy: 0.8889 - val_loss: 0.5654\n",
      "Epoch 28/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8734 - loss: 0.4246 - val_accuracy: 0.9037 - val_loss: 0.5340\n",
      "Epoch 29/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8872 - loss: 0.4029 - val_accuracy: 0.9111 - val_loss: 0.5041\n",
      "Epoch 30/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8937 - loss: 0.4108 - val_accuracy: 0.9111 - val_loss: 0.4688\n",
      "Epoch 31/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8937 - loss: 0.3596 - val_accuracy: 0.9037 - val_loss: 0.4441\n",
      "Epoch 32/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8895 - loss: 0.3603 - val_accuracy: 0.8889 - val_loss: 0.4192\n",
      "Epoch 33/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8933 - loss: 0.3869 - val_accuracy: 0.8889 - val_loss: 0.3988\n",
      "Epoch 34/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8782 - loss: 0.3504 - val_accuracy: 0.9111 - val_loss: 0.3769\n",
      "Epoch 35/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8896 - loss: 0.3479 - val_accuracy: 0.9185 - val_loss: 0.3496\n",
      "Epoch 36/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.3393 - val_accuracy: 0.9185 - val_loss: 0.3348\n",
      "Epoch 37/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9010 - loss: 0.3764 - val_accuracy: 0.9185 - val_loss: 0.3213\n",
      "Epoch 38/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9057 - loss: 0.3161 - val_accuracy: 0.9037 - val_loss: 0.3042\n",
      "Epoch 39/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.3218 - val_accuracy: 0.9037 - val_loss: 0.2897\n",
      "Epoch 40/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2869 - val_accuracy: 0.9037 - val_loss: 0.2855\n",
      "Epoch 41/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8982 - loss: 0.3124 - val_accuracy: 0.9111 - val_loss: 0.2745\n",
      "Epoch 42/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9367 - loss: 0.2714 - val_accuracy: 0.9259 - val_loss: 0.2649\n",
      "Epoch 43/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9295 - loss: 0.2499 - val_accuracy: 0.9259 - val_loss: 0.2542\n",
      "Epoch 44/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8981 - loss: 0.2805 - val_accuracy: 0.9111 - val_loss: 0.2543\n",
      "Epoch 45/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9137 - loss: 0.2944 - val_accuracy: 0.9259 - val_loss: 0.2599\n",
      "Epoch 46/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.2853 - val_accuracy: 0.9259 - val_loss: 0.2506\n",
      "Epoch 47/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2871 - val_accuracy: 0.9185 - val_loss: 0.2481\n",
      "Epoch 48/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9382 - loss: 0.2337 - val_accuracy: 0.9111 - val_loss: 0.2513\n",
      "Epoch 49/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9029 - loss: 0.3038 - val_accuracy: 0.9333 - val_loss: 0.2402\n",
      "Epoch 50/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.2274 - val_accuracy: 0.9481 - val_loss: 0.2280\n",
      "Epoch 51/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9393 - loss: 0.2385 - val_accuracy: 0.9333 - val_loss: 0.2204\n",
      "Epoch 52/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9343 - loss: 0.2223 - val_accuracy: 0.9259 - val_loss: 0.2160\n",
      "Epoch 53/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9527 - loss: 0.1735 - val_accuracy: 0.9185 - val_loss: 0.2142\n",
      "Epoch 54/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9359 - loss: 0.2060 - val_accuracy: 0.9333 - val_loss: 0.2065\n",
      "Epoch 55/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9394 - loss: 0.2094 - val_accuracy: 0.9259 - val_loss: 0.2106\n",
      "Epoch 56/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9404 - loss: 0.2409 - val_accuracy: 0.9407 - val_loss: 0.1957\n",
      "Epoch 57/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.2174 - val_accuracy: 0.9556 - val_loss: 0.1818\n",
      "Epoch 58/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9309 - loss: 0.2298 - val_accuracy: 0.9481 - val_loss: 0.1859\n",
      "Epoch 59/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9526 - loss: 0.2051 - val_accuracy: 0.9333 - val_loss: 0.1888\n",
      "Epoch 60/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9410 - loss: 0.1899 - val_accuracy: 0.9259 - val_loss: 0.1987\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1608 \n",
      "Test accuracy: 96.429%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model and the scalar + feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to model\\physio_model.h5\n",
      "Saved metadata to model\\physio_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "# make sure the folder exists\n",
    "(Path(MODEL_PATH).parent).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "\n",
    "# pickle the scaler and the channel names\n",
    "with open(METADATA_PATH, \"wb\") as f:\n",
    "    # channels list we used for X is:\n",
    "    feature_names = [f\"s{i}\" for i in range(1,9)] + [\"quat_w\",\"quat_x\",\"quat_y\",\"quat_z\"]\n",
    "    pickle.dump((scaler, feature_names), f)\n",
    "\n",
    "print(\"Saved model to\", MODEL_PATH)\n",
    "print(\"Saved metadata to\", METADATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in data folder: ['artemis_archive', 'convert_old_data.py', 'physio_emg_imu_data_20250429_001144.csv', 'physio_emg_imu_data_20250429_174128.csv', 'physio_emg_imu_data_20250429_175521.csv', 'physio_emg_imu_data_20250430_002614.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from constants import DATA_INPUT_PATH\n",
    "\n",
    "print(\"Files in data folder:\", os.listdir(DATA_INPUT_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CSV: physio_emg_imu_data_20250430_002614.csv\n",
      "Loaded 10533 rows from physio_emg_imu_data_20250430_002614.csv\n",
      "\n",
      "Demo samples:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavish Krishnakumar\\AppData\\Local\\Temp\\ipykernel_31260\\3925246817.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(1, random_state=0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gesture_id</th>\n",
       "      <th>true_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wrist Flexion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Wrist Extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Elbow Flexion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Elbow Extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Hand Close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Hand Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Forearm Pronation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Forearm Supination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gesture_id           true_name\n",
       "0           0                Rest\n",
       "1           1       Wrist Flexion\n",
       "2           2     Wrist Extension\n",
       "3           3       Elbow Flexion\n",
       "4           4     Elbow Extension\n",
       "5           5          Hand Close\n",
       "6           6           Hand Open\n",
       "7           7   Forearm Pronation\n",
       "8           8  Forearm Supination"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features: ['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 'quat_w', 'quat_x', 'quat_y', 'quat_z']\n",
      "\n",
      "Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_id</th>\n",
       "      <th>true_name</th>\n",
       "      <th>pred_id</th>\n",
       "      <th>pred_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rest</td>\n",
       "      <td>5</td>\n",
       "      <td>Hand Close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wrist Flexion</td>\n",
       "      <td>1</td>\n",
       "      <td>Wrist Flexion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Wrist Extension</td>\n",
       "      <td>2</td>\n",
       "      <td>Wrist Extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Elbow Flexion</td>\n",
       "      <td>7</td>\n",
       "      <td>Forearm Pronation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Elbow Extension</td>\n",
       "      <td>4</td>\n",
       "      <td>Elbow Extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Hand Close</td>\n",
       "      <td>5</td>\n",
       "      <td>Hand Close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Hand Open</td>\n",
       "      <td>0</td>\n",
       "      <td>Rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Forearm Pronation</td>\n",
       "      <td>0</td>\n",
       "      <td>Rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Forearm Supination</td>\n",
       "      <td>8</td>\n",
       "      <td>Forearm Supination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_id           true_name  pred_id           pred_name\n",
       "0        0                Rest        5          Hand Close\n",
       "1        1       Wrist Flexion        1       Wrist Flexion\n",
       "2        2     Wrist Extension        2     Wrist Extension\n",
       "3        3       Elbow Flexion        7   Forearm Pronation\n",
       "4        4     Elbow Extension        4     Elbow Extension\n",
       "5        5          Hand Close        5          Hand Close\n",
       "6        6           Hand Open        0                Rest\n",
       "7        7   Forearm Pronation        0                Rest\n",
       "8        8  Forearm Supination        8  Forearm Supination"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demo accuracy (1-sample/class): 56%\n"
     ]
    }
   ],
   "source": [
    "# ─── Demo on latest collected Physio CSV ──────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import DATA_INPUT_PATH, MODEL_PATH, METADATA_PATH, CLASSES\n",
    "\n",
    "# 1) locate the CSV folder and pick the newest file\n",
    "data_dir = Path(DATA_INPUT_PATH)\n",
    "csv_files = list(data_dir.glob(\"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSVs found in {data_dir.resolve()}\")\n",
    "\n",
    "# pick by modification time\n",
    "csv_path = max(csv_files, key=lambda p: p.stat().st_mtime)\n",
    "print(\"Using CSV:\", csv_path.name)\n",
    "\n",
    "# 2) load it\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Loaded {len(df)} rows from {csv_path.name}\")\n",
    "\n",
    "# 3) pick one sample per class\n",
    "demo_df = (\n",
    "    df\n",
    "    .groupby(\"gesture_id\", group_keys=False)\n",
    "    .apply(lambda g: g.sample(1, random_state=0))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "demo_df[\"true_name\"] = demo_df[\"gesture_id\"].map(CLASSES)\n",
    "print(\"\\nDemo samples:\")\n",
    "display(demo_df[[\"gesture_id\",\"true_name\"]])\n",
    "\n",
    "# 4) load scaler + feature list\n",
    "with open(METADATA_PATH, \"rb\") as f:\n",
    "    scaler, feature_names = pickle.load(f)\n",
    "print(\"\\nFeatures:\", feature_names)\n",
    "\n",
    "# 5) load model\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# 6) prepare & predict\n",
    "X_demo = demo_df[feature_names].values\n",
    "X_scaled = scaler.transform(X_demo)\n",
    "preds = model.predict(X_scaled, verbose=0)\n",
    "pred_ids = np.argmax(preds, axis=1)\n",
    "demo_df[\"pred_id\"]   = pred_ids\n",
    "demo_df[\"pred_name\"] = demo_df[\"pred_id\"].map(CLASSES)\n",
    "\n",
    "# 7) show results\n",
    "results = demo_df[[\n",
    "    \"gesture_id\",\"true_name\",\"pred_id\",\"pred_name\"\n",
    "]].rename(columns={\"gesture_id\":\"true_id\"})\n",
    "print(\"\\nPredictions:\")\n",
    "display(results)\n",
    "\n",
    "acc = (demo_df[\"pred_id\"] == demo_df[\"gesture_id\"]).mean()\n",
    "print(f\"\\nDemo accuracy (1-sample/class): {acc:.0%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
